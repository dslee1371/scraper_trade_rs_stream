import streamlit as st
from prometheus_client import CollectorRegistry, Counter, Histogram, Gauge, start_http_server, CONTENT_TYPE_LATEST
import requests
import json
import csv
import time
import pandas as pd
import base64
from datetime import datetime
import plotly.express as px
import io
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Set page config
st.set_page_config(
    page_title="ÎÑ§Ïù¥Î≤Ñ Î∂ÄÎèôÏÇ∞ Îç∞Ïù¥ÌÑ∞ Ïä§ÌÅ¨ÎûòÌçº",
    page_icon="üè¢",
    layout="wide"
)

# Prometheus metrics
registry = CollectorRegistry()

# Counters
api_requests_total = Counter(
    'naver_scraper_api_requests_total',
    'Total number of API requests made',
    ['complex_no', 'status'],
    registry=registry
)

data_fetched_total = Counter(
    'naver_scraper_data_fetched_total',
    'Total number of real estate listings fetched',
    ['complex_no'],
    registry=registry
)

errors_total = Counter(
    'naver_scraper_errors_total',
    'Total number of errors encountered',
    ['error_type', 'complex_no'],
    registry=registry
)

user_actions_total = Counter(
    'naver_scraper_user_actions_total',
    'Total number of user actions',
    ['action_type'],
    registry=registry
)

# Histograms
request_duration_seconds = Histogram(
    'naver_scraper_request_duration_seconds',
    'Time spent on API requests',
    ['complex_no'],
    registry=registry
)

data_processing_duration_seconds = Histogram(
    'naver_scraper_data_processing_duration_seconds',
    'Time spent processing data',
    ['complex_no'],
    registry=registry
)

# Gauges
current_active_users = Gauge(
    'naver_scraper_active_users',
    'Current number of active users',
    registry=registry
)

last_successful_fetch_timestamp = Gauge(
    'naver_scraper_last_successful_fetch_timestamp',
    'Timestamp of last successful data fetch',
    ['complex_no'],
    registry=registry
)

current_data_size = Gauge(
    'naver_scraper_current_data_size',
    'Current size of fetched data',
    ['complex_no'],
    registry=registry
)

# Price statistics gauges
price_statistics = {
    'mean': Gauge('naver_scraper_price_mean_billion', 'Mean price in billions', ['complex_no'], registry=registry),
    'max': Gauge('naver_scraper_price_max_billion', 'Max price in billions', ['complex_no'], registry=registry),
    'min': Gauge('naver_scraper_price_min_billion', 'Min price in billions', ['complex_no'], registry=registry),
    'count': Gauge('naver_scraper_price_count', 'Number of properties with valid prices', ['complex_no'], registry=registry)
}

class PrometheusMetrics:
    def __init__(self):
        self.active_users = 0
        
    def increment_user(self):
        self.active_users += 1
        current_active_users.set(self.active_users)
        
    def decrement_user(self):
        self.active_users = max(0, self.active_users - 1)
        current_active_users.set(self.active_users)

# Global metrics instance
metrics = PrometheusMetrics()

# Start Prometheus server once
if 'prometheus_server_started' not in st.session_state:
    start_http_server(8000, registry=registry)
    st.session_state['prometheus_server_started'] = True
    logger.info("‚úÖ Prometheus HTTP server bound on 0.0.0.0:8000")
else:
    logger.debug("Prometheus HTTP server already running")

def fetch_real_estate_data(complex_no, page=1, max_pages=10):
    """
    Fetch real estate listing data from Naver Land API with Prometheus monitoring
    
    Args:
        complex_no (int): The complex number to fetch data for
        page (int): Starting page number
        max_pages (int): Maximum number of pages to fetch
        
    Returns:
        list: List of real estate listings
    """
    all_articles = []
    complex_str = str(complex_no)
    
    # Track user action
    user_actions_total.labels(action_type='data_fetch').inc()
    metrics.increment_user()
    
    try:
        # Status placeholder for progress updates
        status_placeholder = st.empty()
        progress_bar = st.progress(0)
        
        # Set up the cookies and headers for the request
        cookies = {
            'NAC': 't9neDIhO7XOeC',
            'NACT': '1',
            'NNB': 'PABUYQL3IUEGQ',
            'SRT30': '1745372539',
            'SRT5': '1745372539',
            'page_uid': 'jsmaYlqpsECssZM5/xhssssssCG-013955',
            '_naver_usersession_': '9vysnRea1HFqlM9WDkofSQ==',
            'nhn.realestate.article.rlet_type_cd': 'A01',
            'nhn.realestate.article.trade_type_cd': '""',
            'nhn.realestate.article.ipaddress_city': '4100000000',
            '_fwb': '170rFhWLiFMt8pEQwrRRiAc.1745372608079',
            'landHomeFlashUseYn': 'Y',
            'realestate.beta.lastclick.cortar': '1100000000',
            'REALESTATE': 'Wed%20Apr%2023%202025%2010%3A43%3A32%20GMT%2B0900%20(Korean%20Standard%20Time)',
            'BUC': '5OChbI3YrWOGTT-aRWFAZ1HSNSvpNqoT0h7q2BedePg=',
        }

        headers = {
            'accept': '*/*',
            'accept-language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
            'authorization': 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IlJFQUxFU1RBVEUiLCJpYXQiOjE3NDUzNzI2MTIsImV4cCI6MTc0NTM4MzQxMn0.cAlD7MplsiOZY-Il_aocktdRiDsS77e-zN_VThjwzAo',
            'priority': 'u=1, i',
            'referer': f'https://new.land.naver.com/complexes/{complex_no}?ms=37.6099682,127.1045329,17&a=APT:PRE:ABYG:JGC:OPST&e=RETAIL',
            'sec-ch-ua': '"Google Chrome";v="135", "Not-A.Brand";v="8", "Chromium";v="135"',
            'sec-ch-ua-mobile': '?0',
            'sec-ch-ua-platform': '"Windows"',
            'sec-fetch-dest': 'empty',
            'sec-fetch-mode': 'cors',
            'sec-fetch-site': 'same-origin',
            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36',
        }
        
        # Fetch data from multiple pages
        current_page = page
        while current_page <= max_pages:
            status_placeholder.text(f"ÌéòÏù¥ÏßÄ {current_page}/{max_pages} Îç∞Ïù¥ÌÑ∞ Í∞ÄÏ†∏Ïò§Îäî Ï§ë...")
            progress_bar.progress(current_page / max_pages)
            
            url = f'https://new.land.naver.com/api/articles/complex/{complex_no}?realEstateType=APT%3APRE%3AABYG%3AJGC%3AOPST&tradeType=&tag=%3A%3A%3A%3A%3A%3A%3A%3A&rentPriceMin=0&rentPriceMax=900000000&priceMin=0&priceMax=900000000&areaMin=0&areaMax=900000000&oldBuildYears&recentlyBuildYears&minHouseHoldCount&maxHouseHoldCount&showArticle=false&sameAddressGroup=false&minMaintenanceCost&maxMaintenanceCost&priceType=RETAIL&directions=&page={current_page}&complexNo={complex_no}&buildingNos=&areaNos=&type=list&order=rank'
            
            # Measure request duration
            with request_duration_seconds.labels(complex_no=complex_str).time():
                try:
                    response = requests.get(url, cookies=cookies, headers=headers)
                    response.raise_for_status()  # Raise exception for HTTP errors
                    
                    # Track successful API request
                    api_requests_total.labels(complex_no=complex_str, status='success').inc()
                    
                    data = response.json()
                    
                    # Check if we have reached the end of the data
                    if 'articleList' not in data or not data['articleList']:
                        status_placeholder.text(f"ÌéòÏù¥ÏßÄ {current_page}ÏóêÏÑú Îçî Ïù¥ÏÉÅ Îß§Î¨ºÏù¥ ÏóÜÏäµÎãàÎã§.")
                        break
                        
                    articles = data['articleList']
                    all_articles.extend(articles)
                    
                    # Track data fetched
                    data_fetched_total.labels(complex_no=complex_str).inc(len(articles))
                    
                    status_placeholder.text(f"ÌéòÏù¥ÏßÄ {current_page}ÏóêÏÑú {len(articles)}Í∞ú Îß§Î¨º Ï†ïÎ≥¥Î•º Í∞ÄÏ†∏ÏôîÏäµÎãàÎã§.")
                    
                    # Check if more data is available
                    if not data.get('isMoreData', False):
                        status_placeholder.text("Îçî Ïù¥ÏÉÅ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§.")
                        break
                        
                    # Sleep to avoid hitting rate limits
                    time.sleep(1)
                    current_page += 1
                    
                except requests.exceptions.RequestException as e:
                    # Track failed API request
                    api_requests_total.labels(complex_no=complex_str, status='error').inc()
                    errors_total.labels(error_type='api_request', complex_no=complex_str).inc()
                    status_placeholder.error(f"ÌéòÏù¥ÏßÄ {current_page} Îç∞Ïù¥ÌÑ∞ Í∞ÄÏ†∏Ïò§Í∏∞ Ïã§Ìå®: {e}")
                    logger.error(f"API request failed for complex {complex_no}, page {current_page}: {e}")
                    break
                except json.JSONDecodeError as e:
                    # Track JSON decode error
                    errors_total.labels(error_type='json_decode', complex_no=complex_str).inc()
                    status_placeholder.error(f"ÌéòÏù¥ÏßÄ {current_page} JSON ÎîîÏΩîÎî© Ïã§Ìå®: {e}")
                    logger.error(f"JSON decode failed for complex {complex_no}, page {current_page}: {e}")
                    break
        
        progress_bar.progress(1.0)
        status_placeholder.text(f"Ï¥ù {len(all_articles)}Í∞ú Îß§Î¨º Ï†ïÎ≥¥Î•º Í∞ÄÏ†∏ÏôîÏäµÎãàÎã§.")
        
        if all_articles:
            # Update successful fetch timestamp
            last_successful_fetch_timestamp.labels(complex_no=complex_str).set(time.time())
            # Update current data size
            current_data_size.labels(complex_no=complex_str).set(len(all_articles))
            
        return all_articles
        
    except Exception as e:
        errors_total.labels(error_type='general', complex_no=complex_str).inc()
        logger.error(f"General error in fetch_real_estate_data: {e}")
        st.error(f"Îç∞Ïù¥ÌÑ∞Î•º Í∞ÄÏ†∏Ïò§Îäî Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {e}")
        return []
    finally:
        metrics.decrement_user()

def clean_price(price_str):
    """
    Clean and standardize Korean real estate price strings
    Examples:
    - "5Ïñµ" -> "5.00" (5Ïñµ Ïõê, or 500 million won)
    - "5Ïñµ 2,000" -> "5.20" (5Ïñµ 2Ï≤úÎßå Ïõê, or 520 million won)
    """
    if not price_str:
        return ""
    
    # Replace Korean currency symbols/words and standardize
    price_str = price_str.replace("Ïñµ", "").strip()
    
    # Handle price formats like "5Ïñµ 2,000"
    parts = price_str.split()
    if len(parts) == 2:
        try:
            billions = float(parts[0])
            # In Korean real estate, the second part is already in units of 10,000 won (Îßå Ïõê)
            # So for "5Ïñµ 2,000", the 2,000 means 2,000Îßå Ïõê (20 million won)
            thousands = float(parts[1].replace(",", "")) / 10000
            return f"{billions + thousands:.2f}"
        except (ValueError, IndexError):
            return price_str
    
    try:
        return f"{float(price_str):.2f}"
    except ValueError:
        return price_str

def process_data(articles, complex_no):
    """Process the raw articles into a pandas DataFrame with monitoring"""
    if not articles:
        return pd.DataFrame()
    
    complex_str = str(complex_no)
    
    # Measure data processing duration
    with data_processing_duration_seconds.labels(complex_no=complex_str).time():
        try:
            # Create a list to store processed data
            processed_data = []
            
            for article in articles:
                # Extract relevant fields
                row = {
                    'Îß§Î¨ºÎ≤àÌò∏': article.get('articleNo', ''),
                    'Îß§Î¨ºÎ™Ö': article.get('articleName', ''),
                    'Í±¥Î¨ºÎ™Ö': article.get('buildingName', ''),
                    'Í±∞ÎûòÏú†Ìòï': article.get('tradeTypeName', ''),
                    'Í∞ÄÍ≤©': article.get('dealOrWarrantPrc', ''),
                    'Í∞ÄÍ≤©(Ïñµ)': clean_price(article.get('dealOrWarrantPrc', '')),
                    'Î©¥Ï†ÅÎ™Ö': article.get('areaName', ''),
                    'Í≥µÍ∏âÎ©¥Ï†Å(„é°)': article.get('area1', ''),
                    'Ï†ÑÏö©Î©¥Ï†Å(„é°)': article.get('area2', ''),
                    'Ï∏µÏ†ïÎ≥¥': article.get('floorInfo', ''),
                    'Î∞©Ìñ•': article.get('direction', ''),
                    'ÌÉúÍ∑∏': ', '.join(article.get('tagList', [])) if isinstance(article.get('tagList'), list) else article.get('tagList', ''),
                    'ÌäπÏßï': article.get('articleFeatureDesc', ''),
                    'Î∂ÄÎèôÏÇ∞': article.get('realtorName', ''),
                    'ÌôïÏù∏ÏùºÏûê': article.get('articleConfirmYmd', ''),
                    'ÏúÑÎèÑ': article.get('latitude', ''),
                    'Í≤ΩÎèÑ': article.get('longitude', '')
                }
                processed_data.append(row)
            
            # Convert to DataFrame
            df = pd.DataFrame(processed_data)
            
            # Convert price to numeric for analysis
            df['Í∞ÄÍ≤©(Ïñµ)'] = pd.to_numeric(df['Í∞ÄÍ≤©(Ïñµ)'], errors='coerce')
            
            # Update price statistics metrics
            price_data = df['Í∞ÄÍ≤©(Ïñµ)'].dropna()
            if not price_data.empty:
                price_statistics['mean'].labels(complex_no=complex_str).set(price_data.mean())
                price_statistics['max'].labels(complex_no=complex_str).set(price_data.max())
                price_statistics['min'].labels(complex_no=complex_str).set(price_data.min())
                price_statistics['count'].labels(complex_no=complex_str).set(len(price_data))
            
            return df
            
        except Exception as e:
            errors_total.labels(error_type='data_processing', complex_no=complex_str).inc()
            logger.error(f"Data processing error for complex {complex_no}: {e}")
            st.error(f"Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {e}")
            return pd.DataFrame()

def create_download_link(df, filename="data.csv"):
    """Generate a download link for the dataframe"""
    try:
        user_actions_total.labels(action_type='download').inc()
        csv = df.to_csv(index=False, encoding='utf-8-sig')
        b64 = base64.b64encode(csv.encode('utf-8-sig')).decode()
        href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">CSV ÌååÏùº Îã§Ïö¥Î°úÎìú</a>'
        return href
    except Exception as e:
        errors_total.labels(error_type='download', complex_no='unknown').inc()
        logger.error(f"Download link creation error: {e}")
        return "Îã§Ïö¥Î°úÎìú ÎßÅÌÅ¨ ÏÉùÏÑ± Ïã§Ìå®"

def main():
    # Track page view
    user_actions_total.labels(action_type='page_view').inc()
    
    # Title and description
    st.title("ÎÑ§Ïù¥Î≤Ñ Î∂ÄÎèôÏÇ∞ Îç∞Ïù¥ÌÑ∞ Ïä§ÌÅ¨ÎûòÌçº")
    st.markdown("ÎÑ§Ïù¥Î≤Ñ Î∂ÄÎèôÏÇ∞ÏóêÏÑú Îß§Î¨º Ï†ïÎ≥¥Î•º ÏàòÏßëÌïòÍ≥† CSV ÌååÏùºÎ°ú Ï†ÄÏû•Ìï©ÎãàÎã§.")
    
    # Prometheus metrics info
    with st.expander("üìä Î™®ÎãàÌÑ∞ÎßÅ Ï†ïÎ≥¥"):
        st.markdown("""
        **Prometheus Î©îÌä∏Î¶≠ ÏÑúÎ≤Ñ**: http://localhost:8000/metrics
        
        **ÏàòÏßëÎêòÎäî Î©îÌä∏Î¶≠:**
        - API ÏöîÏ≤≠ Ïàò Î∞è ÏÑ±Í≥µ/Ïã§Ìå®Ïú®
        - Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ ÏãúÍ∞Ñ
        - ÏóêÎü¨ Î∞úÏÉù ÎπàÎèÑ
        - ÌòÑÏû¨ ÌôúÏÑ± ÏÇ¨Ïö©Ïûê Ïàò
        - Í∞ÄÍ≤© ÌÜµÍ≥Ñ (ÌèâÍ∑†, ÏµúÍ≥†, ÏµúÏ†Ä)
        - ÎßàÏßÄÎßâ ÏÑ±Í≥µÏ†ÅÏù∏ Îç∞Ïù¥ÌÑ∞ ÏàòÏßë ÏãúÍ∞Ñ
        """)
    
    # Sidebar inputs
    st.sidebar.header("Í≤ÄÏÉâ ÏÑ§Ï†ï")
    
    # Complex number input
    complex_no = st.sidebar.text_input(
        "Îã®ÏßÄ Î≤àÌò∏ ÏûÖÎ†•",
        value="131345",
        help="ÎÑ§Ïù¥Î≤Ñ Î∂ÄÎèôÏÇ∞ URLÏóêÏÑú complexes/ Îã§ÏùåÏóê Ïò§Îäî Ïà´ÏûêÏûÖÎãàÎã§. Ïòà: https://new.land.naver.com/complexes/131345"
    )
    
    # Max pages input
    max_pages = st.sidebar.slider(
        "ÏµúÎåÄ ÌéòÏù¥ÏßÄ Ïàò",
        min_value=1,
        max_value=20,
        value=5,
        help="Í∞ÄÏ†∏Ïò¨ ÏµúÎåÄ ÌéòÏù¥ÏßÄ Ïàò"
    )
    
    # Fetch data button
    if st.sidebar.button("Îç∞Ïù¥ÌÑ∞ Í∞ÄÏ†∏Ïò§Í∏∞"):
        if not complex_no:
            st.error("Îã®ÏßÄ Î≤àÌò∏Î•º ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî.")
            return
            
        try:
            complex_no = int(complex_no)
        except ValueError:
            st.error("Îã®ÏßÄ Î≤àÌò∏Îäî Ïà´ÏûêÏó¨Ïïº Ìï©ÎãàÎã§.")
            errors_total.labels(error_type='input_validation', complex_no='invalid').inc()
            return
            
        # Fetch data
        with st.spinner("Îç∞Ïù¥ÌÑ∞ Í∞ÄÏ†∏Ïò§Îäî Ï§ë..."):
            articles = fetch_real_estate_data(complex_no, max_pages=max_pages)
            
            if not articles:
                st.warning("Îç∞Ïù¥ÌÑ∞Î•º Í∞ÄÏ†∏Ïò§ÏßÄ Î™ªÌñàÏäµÎãàÎã§.")
                return
                
            # Process data
            df = process_data(articles, complex_no)
            
            # Store in session state
            st.session_state.df = df
            st.session_state.complex_no = complex_no
            
            # Success message
            st.success(f"Ï¥ù {len(df)} Í∞úÏùò Îß§Î¨º Ï†ïÎ≥¥Î•º Í∞ÄÏ†∏ÏôîÏäµÎãàÎã§!")
    
    # Display data if available
    if 'df' in st.session_state and not st.session_state.df.empty:
        df = st.session_state.df
        complex_no = st.session_state.complex_no
        
        # Create tabs
        tab1, tab2, tab3, tab4 = st.tabs(["Îç∞Ïù¥ÌÑ∞", "Î∂ÑÏÑù", "ÏãúÍ∞ÅÌôî", "Î™®ÎãàÌÑ∞ÎßÅ"])
        
        with tab1:
            user_actions_total.labels(action_type='view_data').inc()
            
            # Download button
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"naver_real_estate_data_{complex_no}_{timestamp}.csv"
            st.markdown(create_download_link(df, filename), unsafe_allow_html=True)
            
            # Display dataframe
            st.dataframe(df, use_container_width=True)
        
        with tab2:
            user_actions_total.labels(action_type='view_analysis').inc()
            
            st.subheader("Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù")
            
            # Basic statistics
            if 'Í∞ÄÍ≤©(Ïñµ)' in df.columns:
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("ÌèâÍ∑† Í∞ÄÍ≤©(Ïñµ)", f"{df['Í∞ÄÍ≤©(Ïñµ)'].mean():.2f}")
                
                with col2:
                    st.metric("ÏµúÍ≥† Í∞ÄÍ≤©(Ïñµ)", f"{df['Í∞ÄÍ≤©(Ïñµ)'].max():.2f}")
                
                with col3:
                    st.metric("ÏµúÏ†Ä Í∞ÄÍ≤©(Ïñµ)", f"{df['Í∞ÄÍ≤©(Ïñµ)'].min():.2f}")
            
            # Group by analysis
            st.subheader("Í±∞Îûò Ïú†ÌòïÎ≥Ñ ÌèâÍ∑† Í∞ÄÍ≤©")
            if 'Í±∞ÎûòÏú†Ìòï' in df.columns and 'Í∞ÄÍ≤©(Ïñµ)' in df.columns:
                trade_type_avg = df.groupby('Í±∞ÎûòÏú†Ìòï')['Í∞ÄÍ≤©(Ïñµ)'].agg(['mean', 'count']).reset_index()
                trade_type_avg.columns = ['Í±∞ÎûòÏú†Ìòï', 'ÌèâÍ∑† Í∞ÄÍ≤©(Ïñµ)', 'Îß§Î¨º Ïàò']
                st.dataframe(trade_type_avg, use_container_width=True)
            
            st.subheader("Î©¥Ï†ÅÎ≥Ñ ÌèâÍ∑† Í∞ÄÍ≤©")
            if 'Ï†ÑÏö©Î©¥Ï†Å(„é°)' in df.columns and 'Í∞ÄÍ≤©(Ïñµ)' in df.columns:
                # Create bins for area
                df['Î©¥Ï†ÅÍµ¨Í∞Ñ'] = pd.cut(
                    df['Ï†ÑÏö©Î©¥Ï†Å(„é°)'], 
                    bins=[0, 30, 60, 85, 120, 200],
                    labels=['~30„é°', '30~60„é°', '60~85„é°', '85~120„é°', '120„é°~']
                )
                
                area_avg = df.groupby('Î©¥Ï†ÅÍµ¨Í∞Ñ')['Í∞ÄÍ≤©(Ïñµ)'].agg(['mean', 'count']).reset_index()
                area_avg.columns = ['Î©¥Ï†ÅÍµ¨Í∞Ñ', 'ÌèâÍ∑† Í∞ÄÍ≤©(Ïñµ)', 'Îß§Î¨º Ïàò']
                st.dataframe(area_avg, use_container_width=True)
        
        with tab3:
            user_actions_total.labels(action_type='view_visualization').inc()
            
            st.subheader("Îç∞Ïù¥ÌÑ∞ ÏãúÍ∞ÅÌôî")
            
            if 'Í∞ÄÍ≤©(Ïñµ)' in df.columns:
                # Price distribution
                st.subheader("Í∞ÄÍ≤© Î∂ÑÌè¨")
                fig = px.histogram(df, x='Í∞ÄÍ≤©(Ïñµ)', nbins=20, title="Í∞ÄÍ≤© Î∂ÑÌè¨")
                st.plotly_chart(fig, use_container_width=True)
                
                # Price by floor
                if 'Ï∏µÏ†ïÎ≥¥' in df.columns:
                    # Extract floor number
                    df['Ï∏µ'] = df['Ï∏µÏ†ïÎ≥¥'].str.extract(r'(\d+)/')
                    df['Ï∏µ'] = pd.to_numeric(df['Ï∏µ'], errors='coerce')
                    
                    # Filter out rows with missing floor
                    floor_df = df.dropna(subset=['Ï∏µ'])
                    
                    if not floor_df.empty:
                        st.subheader("Ï∏µÎ≥Ñ Í∞ÄÍ≤©")
                        fig = px.scatter(
                            floor_df, 
                            x='Ï∏µ', 
                            y='Í∞ÄÍ≤©(Ïñµ)',
                            color='Í±∞ÎûòÏú†Ìòï' if 'Í±∞ÎûòÏú†Ìòï' in floor_df.columns else None,
                            title="Ï∏µÎ≥Ñ Í∞ÄÍ≤©",
                            labels={'Ï∏µ': 'Ï∏µ', 'Í∞ÄÍ≤©(Ïñµ)': 'Í∞ÄÍ≤©(Ïñµ)'}
                        )
                        st.plotly_chart(fig, use_container_width=True)
                
                # Price by area
                if 'Ï†ÑÏö©Î©¥Ï†Å(„é°)' in df.columns:
                    st.subheader("Î©¥Ï†ÅÎ≥Ñ Í∞ÄÍ≤©")
                    fig = px.scatter(
                        df, 
                        x='Ï†ÑÏö©Î©¥Ï†Å(„é°)', 
                        y='Í∞ÄÍ≤©(Ïñµ)',
                        color='Í±∞ÎûòÏú†Ìòï' if 'Í±∞ÎûòÏú†Ìòï' in df.columns else None,
                        title="Î©¥Ï†ÅÎ≥Ñ Í∞ÄÍ≤©",
                        labels={'Ï†ÑÏö©Î©¥Ï†Å(„é°)': 'Ï†ÑÏö©Î©¥Ï†Å(„é°)', 'Í∞ÄÍ≤©(Ïñµ)': 'Í∞ÄÍ≤©(Ïñµ)'}
                    )
                    st.plotly_chart(fig, use_container_width=True)
                
                # Map view
                if 'ÏúÑÎèÑ' in df.columns and 'Í≤ΩÎèÑ' in df.columns:
                    st.subheader("ÏßÄÎèÑ Î≥¥Í∏∞")
                    
                    # Convert lat/lon to numeric
                    df['ÏúÑÎèÑ'] = pd.to_numeric(df['ÏúÑÎèÑ'], errors='coerce')
                    df['Í≤ΩÎèÑ'] = pd.to_numeric(df['Í≤ΩÎèÑ'], errors='coerce')
                    
                    # Filter out rows with missing coordinates
                    map_df = df.dropna(subset=['ÏúÑÎèÑ', 'Í≤ΩÎèÑ'])
                    
                    if not map_df.empty:
                        fig = px.scatter_mapbox(
                            map_df,
                            lat='ÏúÑÎèÑ',
                            lon='Í≤ΩÎèÑ',
                            color='Í∞ÄÍ≤©(Ïñµ)',
                            size='Ï†ÑÏö©Î©¥Ï†Å(„é°)' if 'Ï†ÑÏö©Î©¥Ï†Å(„é°)' in map_df.columns else None,
                            hover_name='Îß§Î¨ºÎ™Ö',
                            hover_data=['Í∞ÄÍ≤©', 'Í±∞ÎûòÏú†Ìòï', 'Ï∏µÏ†ïÎ≥¥', 'Ï†ÑÏö©Î©¥Ï†Å(„é°)'],
                            color_continuous_scale=px.colors.sequential.Plasma,
                            zoom=15,
                            mapbox_style="carto-positron"
                        )
                        st.plotly_chart(fig, use_container_width=True)
        
        with tab4:
            user_actions_total.labels(action_type='view_monitoring').inc()
            
            st.subheader("üìä Ïã§ÏãúÍ∞Ñ Î™®ÎãàÌÑ∞ÎßÅ")
            
            # Metrics endpoint info
            st.info("Prometheus Î©îÌä∏Î¶≠ÏùÄ http://localhost:8000/metrics ÏóêÏÑú ÌôïÏù∏Ìï† Ïàò ÏûàÏäµÎãàÎã§.")
            
            # Display current metrics (simulated view)
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("ÌòÑÏû¨ ÏÑ∏ÏÖò ÌÜµÍ≥Ñ")
                if 'df' in st.session_state:
                    st.metric("Îç∞Ïù¥ÌÑ∞ Í±¥Ïàò", len(st.session_state.df))
                    st.metric("Îã®ÏßÄ Î≤àÌò∏", st.session_state.complex_no)
                    
                    # Price statistics
                    if 'Í∞ÄÍ≤©(Ïñµ)' in st.session_state.df.columns:
                        price_data = st.session_state.df['Í∞ÄÍ≤©(Ïñµ)'].dropna()
                        if not price_data.empty:
                            st.metric("ÌèâÍ∑† Í∞ÄÍ≤©(Ïñµ)", f"{price_data.mean():.2f}")
                            st.metric("ÏµúÍ≥† Í∞ÄÍ≤©(Ïñµ)", f"{price_data.max():.2f}")
                            st.metric("ÏµúÏ†Ä Í∞ÄÍ≤©(Ïñµ)", f"{price_data.min():.2f}")
            
            with col2:
                st.subheader("ÏãúÏä§ÌÖú Ï†ïÎ≥¥")
                st.metric("Prometheus ÏÑúÎ≤Ñ", "Ìè¨Ìä∏ 8000ÏóêÏÑú Ïã§Ìñâ Ï§ë")
                st.metric("ÌòÑÏû¨ ÏãúÍ∞Ñ", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                
                # Show sample metrics
                st.subheader("ÏàòÏßëÎêòÎäî Î©îÌä∏Î¶≠ ÏòàÏãú")
                st.code("""
# API ÏöîÏ≤≠ ÌöüÏàò
naver_scraper_api_requests_total{complex_no="131345",status="success"} 15

# Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ ÏãúÍ∞Ñ
naver_scraper_data_processing_duration_seconds{complex_no="131345"} 0.245

# ÏóêÎü¨ Î∞úÏÉù ÌöüÏàò
naver_scraper_errors_total{error_type="api_request",complex_no="131345"} 0

# ÌòÑÏû¨ ÌôúÏÑ± ÏÇ¨Ïö©Ïûê Ïàò
naver_scraper_active_users 2

# Í∞ÄÍ≤© ÌÜµÍ≥Ñ
naver_scraper_price_mean_billion{complex_no="131345"} 8.45
naver_scraper_price_max_billion{complex_no="131345"} 15.20
naver_scraper_price_min_billion{complex_no="131345"} 3.80

# ÎßàÏßÄÎßâ ÏÑ±Í≥µÏ†ÅÏù∏ Îç∞Ïù¥ÌÑ∞ ÏàòÏßë ÏãúÍ∞Ñ
naver_scraper_last_successful_fetch_timestamp{complex_no="131345"} 1735123456
                """)
                
            # Grafana dashboard suggestion
            st.subheader("üéØ Grafana ÎåÄÏãúÎ≥¥Îìú ÏÑ§Ï†ï")
            st.markdown("""
            **Ï∂îÏ≤ú Grafana ÏøºÎ¶¨:**
            
            1. **API ÏÑ±Í≥µÎ•†**:
            ```
            rate(naver_scraper_api_requests_total{status="success"}[5m]) / 
            rate(naver_scraper_api_requests_total[5m]) * 100
            ```
            
            2. **ÌèâÍ∑† ÏùëÎãµ ÏãúÍ∞Ñ**:
            ```
            histogram_quantile(0.95, rate(naver_scraper_request_duration_seconds_bucket[5m]))
            ```
            
            3. **ÏãúÍ∞ÑÎãπ ÏóêÎü¨Ïú®**:
            ```
            rate(naver_scraper_errors_total[1h])
            ```
            
            4. **ÌôúÏÑ± ÏÇ¨Ïö©Ïûê Ïàò**:
            ```
            naver_scraper_active_users
            ```
            """)
            
            # Alerting rules suggestion
            st.subheader("üö® Ï∂îÏ≤ú ÏïåÎ¶º Í∑úÏπô")
            st.markdown("""
            **Prometheus AlertManager Í∑úÏπô:**
            
            ```yaml
            groups:
            - name: naver_scraper_alerts
              rules:
              - alert: HighErrorRate
                expr: rate(naver_scraper_errors_total[5m]) > 0.1
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: "ÎÑ§Ïù¥Î≤Ñ Ïä§ÌÅ¨ÎûòÌçº ÏóêÎü¨Ïú® Ï¶ùÍ∞Ä"
                  description: "ÏóêÎü¨Ïú®Ïù¥ {{ $value }}% ÏûÖÎãàÎã§"
                  
              - alert: APIRequestFailure
                expr: rate(naver_scraper_api_requests_total{status="error"}[5m]) > 0.05
                for: 1m
                labels:
                  severity: critical
                annotations:
                  summary: "API ÏöîÏ≤≠ Ïã§Ìå®Ïú® Ï¶ùÍ∞Ä"
                  
              - alert: DataProcessingTimeout
                expr: histogram_quantile(0.95, rate(naver_scraper_data_processing_duration_seconds_bucket[5m])) > 10
                for: 3m
                labels:
                  severity: warning
                annotations:
                  summary: "Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ ÏãúÍ∞Ñ Ï¥àÍ≥º"
            ```
            """)

if __name__ == "__main__":
    main()

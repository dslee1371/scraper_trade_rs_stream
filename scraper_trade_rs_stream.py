import threading
import time
import base64
import requests
import json
import csv
import io
from datetime import datetime

import streamlit as st
import pandas as pd
import plotly.express as px

from prometheus_client import (
    CollectorRegistry,
    Counter,
    Histogram,
    Gauge,
    start_http_server
)

# â”€â”€â”€ Prometheus Metrics ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
registry = CollectorRegistry()

PAGE_FETCH_COUNTER = Counter(
    'naver_scraper_pages_fetched_total',
    'ì´ ë„¤ì´ë²„ ë¶€ë™ì‚° í˜ì´ì§€ ìš”ì²­ íšŸìˆ˜',
    registry=registry
)
PAGE_FETCH_DURATION = Histogram(
    'naver_scraper_page_fetch_duration_seconds',
    'í˜ì´ì§€ ìš”ì²­ ì§€ì—° ì‹œê°„(ì´ˆ)',
    buckets=(0.1, 0.5, 1, 2, 5, 10),
    registry=registry
)
ARTICLE_COUNTER = Counter(
    'naver_scraper_articles_processed_total',
    'ì²˜ë¦¬ëœ ë§¤ë¬¼(article) ì´ ê±´ìˆ˜',
    registry=registry
)
LAST_PAGE_ARTICLE_GAUGE = Gauge(
    'naver_scraper_last_page_article_count',
    'ë§ˆì§€ë§‰ í˜ì´ì§€ì—ì„œ ê°€ì ¸ì˜¨ ë§¤ë¬¼(article) ìˆ˜',
    registry=registry
)


def start_metrics_server():
    """Prometheus metrics ì„œë²„ ì‹œì‘ (í¬íŠ¸ 8000)"""
    # registry ì¸ìë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤
    start_http_server(8000, registry=registry)
    print("Prometheus metrics server started on :8000")

# ë°±ê·¸ë¼ìš´ë“œì—ì„œ metrics ì„œë²„ êµ¬ë™
import threading
threading.Thread(target=start_metrics_server, daemon=True).start()

# â”€â”€â”€ Streamlit ì•± ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="ë„¤ì´ë²„ ë¶€ë™ì‚° ë°ì´í„° ìŠ¤í¬ë˜í¼",
    page_icon="ğŸ¢",
    layout="wide"
)

st.title("ë„¤ì´ë²„ ë¶€ë™ì‚° ë°ì´í„° ìŠ¤í¬ë˜í¼")
st.markdown("ë„¤ì´ë²„ ë¶€ë™ì‚°ì—ì„œ ë§¤ë¬¼ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.")

def fetch_real_estate_data(complex_no, page=1, max_pages=10):
    all_articles = []
    status_placeholder = st.empty()
    progress_bar = st.progress(0)

    cookies = {
        'NAC': 't9neDIhO7XOeC',
        'NACT': '1',
        'NNB': 'PABUYQL3IUEGQ',
        'SRT30': '1745372539',
        'SRT5': '1745372539',
        'page_uid': 'jsmaYlqpsECssZM5/xhssssssCG-013955',
        '_naver_usersession_': '9vysnRea1HFqlM9WDkofSQ==',
        'nhn.realestate.article.rlet_type_cd': 'A01',
        'nhn.realestate.article.trade_type_cd': '""',
        'nhn.realestate.article.ipaddress_city': '4100000000',
        '_fwb': '170rFhWLiFMt8pEQwrRRiAc.1745372608079',
        'landHomeFlashUseYn': 'Y',
        'realestate.beta.lastclick.cortar': '1100000000',
        'REALESTATE': 'Wed%20Apr%2023%202025%2010%3A43%3A32%20GMT%2B0900%20(Korean%20Standard%20Time)',
        'BUC': '5OChbI3YrWOGTT-aRWFAZ1HSNSvpNqoT0h7q2BedePg=',
    }

    headers = {
        'accept': '*/*',
        'accept-language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
        'authorization': 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IlJFQUxFU1RBVEUiLCJpYXQiOjE3NDUzNzI2MTIsImV4cCI6MTc0NTM4MzQxMn0.cAlD7MplsiOZY-Il_aocktdRiDsS77e-zN_VThjwzAo',
        'priority': 'u=1, i',
        'referer': f'https://new.land.naver.com/complexes/{complex_no}?ms=37.6099682,127.1045329,17&a=APT:PRE:ABYG:JGC:OPST&e=RETAIL',
        'sec-ch-ua': '"Google Chrome";v="135", "Not-A.Brand";v="8", "Chromium";v="135"',
        'sec-ch-ua-mobile': '?0',
        'sec-ch-ua-platform': '"Windows"',
        'sec-fetch-dest': 'empty',
        'sec-fetch-mode': 'cors',
        'sec-fetch-site': 'same-origin',
        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36',
    }

    current_page = page
    while current_page <= max_pages:
        status_placeholder.text(f"í˜ì´ì§€ {current_page}/{max_pages} ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        progress_bar.progress(current_page / max_pages)

        url = (
            f'https://new.land.naver.com/api/articles/complex/{complex_no}'
            f'?realEstateType=APT%3APRE%3AABYG%3AJGC%3AOPST&tradeType=&'
            f'tag=%3A%3A%3A%3A%3A%3A%3A%3A&rentPriceMin=0&rentPriceMax=900000000'
            f'&priceMin=0&priceMax=900000000&areaMin=0&areaMax=900000000'
            f'&oldBuildYears&recentlyBuildYears&minHouseHoldCount&maxHouseHoldCount'
            f'&showArticle=false&sameAddressGroup=false&minMaintenanceCost'
            f'&maxMaintenanceCost&priceType=RETAIL&directions=&page={current_page}'
            f'&complexNo={complex_no}&buildingNos=&areaNos=&type=list&order=rank'
        )

        with PAGE_FETCH_DURATION.time():
            try:
                response = requests.get(url, cookies=cookies, headers=headers)
                response.raise_for_status()
            except Exception as e:
                status_placeholder.error(f"í˜ì´ì§€ {current_page} ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
                break

        PAGE_FETCH_COUNTER.inc()
        data = response.json()

        articles = data.get('articleList', [])
        if not articles:
            status_placeholder.text("ë” ì´ìƒ ë§¤ë¬¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            break

        all_articles.extend(articles)
        ARTICLE_COUNTER.inc(len(articles))
        LAST_PAGE_ARTICLE_GAUGE.set(len(articles))

        status_placeholder.text(f"í˜ì´ì§€ {current_page}ì—ì„œ {len(articles)}ê°œ ë§¤ë¬¼ ì •ë³´ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
        if not data.get('isMoreData', False):
            status_placeholder.text("ë§ˆì§€ë§‰ í˜ì´ì§€ì…ë‹ˆë‹¤.")
            break

        time.sleep(1)
        current_page += 1

    progress_bar.progress(1.0)
    status_placeholder.text(f"ì´ {len(all_articles)}ê°œ ë§¤ë¬¼ ì •ë³´ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
    return all_articles

def clean_price(price_str):
    if not price_str:
        return ""
    price_str = price_str.replace("ì–µ", " ").strip()
    parts = price_str.split()
    if len(parts) == 2:
        try:
            billions = float(parts[0])
            thousands = float(parts[1].replace(",", "")) / 10000
            return f"{billions + thousands:.2f}"
        except (ValueError, IndexError):
            return price_str
    try:
        return f"{float(price_str):.2f}"
    except ValueError:
        return price_str

def process_data(articles):
    if not articles:
        return pd.DataFrame()
    processed_data = []
    for article in articles:
        processed_data.append({
            'ë§¤ë¬¼ë²ˆí˜¸': article.get('articleNo', ''),
            'ë§¤ë¬¼ëª…': article.get('articleName', ''),
            'ê±´ë¬¼ëª…': article.get('buildingName', ''),
            'ê±°ë˜ìœ í˜•': article.get('tradeTypeName', ''),
            'ê°€ê²©': article.get('dealOrWarrantPrc', ''),
            'ê°€ê²©(ì–µ)': clean_price(article.get('dealOrWarrantPrc', '')),
            'ë©´ì ëª…': article.get('areaName', ''),
            'ê³µê¸‰ë©´ì (ã¡)': article.get('area1', ''),
            'ì „ìš©ë©´ì (ã¡)': article.get('area2', ''),
            'ì¸µì •ë³´': article.get('floorInfo', ''),
            'ë°©í–¥': article.get('direction', ''),
            'íƒœê·¸': ', '.join(article.get('tagList', [])) if isinstance(article.get('tagList'), list) else article.get('tagList', ''),
            'íŠ¹ì§•': article.get('articleFeatureDesc', ''),
            'ë¶€ë™ì‚°': article.get('realtorName', ''),
            'í™•ì¸ì¼ì': article.get('articleConfirmYmd', ''),
            'ìœ„ë„': article.get('latitude', ''),
            'ê²½ë„': article.get('longitude', '')
        })
    df = pd.DataFrame(processed_data)
    df['ê°€ê²©(ì–µ)'] = pd.to_numeric(df['ê°€ê²©(ì–µ)'], errors='coerce')
    return df

def create_download_link(df, filename="data.csv"):
    csv_data = df.to_csv(index=False, encoding='utf-8-sig')
    b64 = base64.b64encode(csv_data.encode('utf-8-sig')).decode()
    return f'<a href="data:file/csv;base64,{b64}" download="{filename}">CSV íŒŒì¼ ë‹¤ìš´ë¡œë“œ</a>'

def main():
    st.sidebar.header("ê²€ìƒ‰ ì„¤ì •")
    complex_no = st.sidebar.text_input(
        "ë‹¨ì§€ ë²ˆí˜¸ ì…ë ¥",
        value="131345",
        help="ë„¤ì´ë²„ ë¶€ë™ì‚° URLì—ì„œ complexes/ ë‹¤ìŒì— ì˜¤ëŠ” ìˆ«ìì…ë‹ˆë‹¤."
    )
    max_pages = st.sidebar.slider(
        "ìµœëŒ€ í˜ì´ì§€ ìˆ˜",
        min_value=1,
        max_value=20,
        value=5,
        help="ê°€ì ¸ì˜¬ ìµœëŒ€ í˜ì´ì§€ ìˆ˜"
    )

    if st.sidebar.button("ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"):
        try:
            cn = int(complex_no)
        except ValueError:
            st.error("ë‹¨ì§€ ë²ˆí˜¸ëŠ” ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤.")
            return

        with st.spinner("ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
            articles = fetch_real_estate_data(cn, max_pages=max_pages)
            if not articles:
                st.warning("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return
            df = process_data(articles)
            st.session_state.df = df
            st.session_state.cn = cn
            st.success(f"ì´ {len(df)} ê°œì˜ ë§¤ë¬¼ ì •ë³´ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤!")

    if 'df' in st.session_state and not st.session_state.df.empty:
        df = st.session_state.df
        cn = st.session_state.cn
        tab1, tab2, tab3 = st.tabs(["ë°ì´í„°", "ë¶„ì„", "ì‹œê°í™”"])

        with tab1:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"naver_real_estate_data_{cn}_{timestamp}.csv"
            st.markdown(create_download_link(df, filename), unsafe_allow_html=True)
            st.dataframe(df, use_container_width=True)

        with tab2:
            st.subheader("ë°ì´í„° ë¶„ì„")
            if 'ê°€ê²©(ì–µ)' in df.columns:
                c1, c2, c3 = st.columns(3)
                c1.metric("í‰ê·  ê°€ê²©(ì–µ)", f"{df['ê°€ê²©(ì–µ)'].mean():.2f}")
                c2.metric("ìµœê³  ê°€ê²©(ì–µ)", f"{df['ê°€ê²©(ì–µ)'].max():.2f}")
                c3.metric("ìµœì € ê°€ê²©(ì–µ)", f"{df['ê°€ê²©(ì–µ)'].min():.2f}")

            st.subheader("ê±°ë˜ ìœ í˜•ë³„ í‰ê·  ê°€ê²©")
            if 'ê±°ë˜ìœ í˜•' in df.columns:
                trade_avg = df.groupby('ê±°ë˜ìœ í˜•')['ê°€ê²©(ì–µ)'].agg(['mean','count']).reset_index()
                trade_avg.columns = ['ê±°ë˜ìœ í˜•','í‰ê·  ê°€ê²©(ì–µ)','ë§¤ë¬¼ ìˆ˜']
                st.dataframe(trade_avg, use_container_width=True)

            st.subheader("ë©´ì ë³„ í‰ê·  ê°€ê²©")
            if 'ì „ìš©ë©´ì (ã¡)' in df.columns:
                df['ë©´ì êµ¬ê°„'] = pd.cut(df['ì „ìš©ë©´ì (ã¡)'], bins=[0,30,60,85,120,200],
                                      labels=['~30ã¡','30~60ã¡','60~85ã¡','85~120ã¡','120ã¡~'])
                area_avg = df.groupby('ë©´ì êµ¬ê°„')['ê°€ê²©(ì–µ)'].agg(['mean','count']).reset_index()
                area_avg.columns=['ë©´ì êµ¬ê°„','í‰ê·  ê°€ê²©(ì–µ)','ë§¤ë¬¼ ìˆ˜']
                st.dataframe(area_avg, use_container_width=True)

        with tab3:
            st.subheader("ë°ì´í„° ì‹œê°í™”")
            if 'ê°€ê²©(ì–µ)' in df.columns:
                st.subheader("ê°€ê²© ë¶„í¬")
                fig = px.histogram(df, x='ê°€ê²©(ì–µ)', nbins=20, title="ê°€ê²© ë¶„í¬")
                st.plotly_chart(fig, use_container_width=True)

                if 'ì¸µì •ë³´' in df.columns:
                    df['ì¸µ'] = df['ì¸µì •ë³´'].str.extract(r'(\d+)/').astype(float, errors='ignore')
                    fl = df.dropna(subset=['ì¸µ'])
                    if not fl.empty:
                        st.subheader("ì¸µë³„ ê°€ê²©")
                        fig = px.scatter(fl, x='ì¸µ', y='ê°€ê²©(ì–µ)',
                                         color='ê±°ë˜ìœ í˜•' if 'ê±°ë˜ìœ í˜•' in fl.columns else None,
                                         title="ì¸µë³„ ê°€ê²©",
                                         labels={'ì¸µ':'ì¸µ','ê°€ê²©(ì–µ)':'ê°€ê²©(ì–µ)'})
                        st.plotly_chart(fig, use_container_width=True)

                if 'ì „ìš©ë©´ì (ã¡)' in df.columns:
                    st.subheader("ë©´ì ë³„ ê°€ê²©")
                    fig = px.scatter(df, x='ì „ìš©ë©´ì (ã¡)', y='ê°€ê²©(ì–µ)',
                                     color='ê±°ë˜ìœ í˜•' if 'ê±°ë˜ìœ í˜•' in df.columns else None,
                                     title="ë©´ì ë³„ ê°€ê²©",
                                     labels={'ì „ìš©ë©´ì (ã¡)':'ì „ìš©ë©´ì (ã¡)','ê°€ê²©(ì–µ)':'ê°€ê²©(ì–µ)'})
                    st.plotly_chart(fig, use_container_width=True)

                if 'ìœ„ë„' in df.columns and 'ê²½ë„' in df.columns:
                    st.subheader("ì§€ë„ ë³´ê¸°")
                    df['ìœ„ë„'] = pd.to_numeric(df['ìœ„ë„'], errors='coerce')
                    df['ê²½ë„'] = pd.to_numeric(df['ê²½ë„'], errors='coerce')
                    mp = df.dropna(subset=['ìœ„ë„','ê²½ë„'])
                    if not mp.empty:
                        fig = px.scatter_mapbox(mp, lat='ìœ„ë„', lon='ê²½ë„',
                                               color='ê°€ê²©(ì–µ)',
                                               size='ì „ìš©ë©´ì (ã¡)' if 'ì „ìš©ë©´ì (ã¡)' in mp.columns else None,
                                               hover_name='ë§¤ë¬¼ëª…',
                                               hover_data=['ê°€ê²©','ê±°ë˜ìœ í˜•','ì¸µì •ë³´','ì „ìš©ë©´ì (ã¡)'],
                                               zoom=15,
                                               mapbox_style="carto-positron")
                        st.plotly_chart(fig, use_container_width=True)

if __name__ == "__main__":
    main()

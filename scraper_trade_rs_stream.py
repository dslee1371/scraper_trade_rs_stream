import threading
import time
import base64
import requests
import json
import csv
import io
from datetime import datetime

import streamlit as st
import pandas as pd
import plotly.express as px

from prometheus_client import (
    CollectorRegistry,
    Counter,
    Histogram,
    Gauge,
    start_http_server,
    generate_latest,
    CONTENT_TYPE_LATEST
)

# â”€â”€â”€ Prometheus Metrics ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì „ì—­ registry ì‚¬ìš©í•˜ì§€ ì•Šê³  ì»¤ìŠ¤í…€ registry ì‚¬ìš©
registry = CollectorRegistry()

PAGE_FETCH_COUNTER = Counter(
    'naver_scraper_pages_fetched_total',
    'ì´ ë„¤ì´ë²„ ë¶€ë™ì‚° í˜ì´ì§€ ìš”ì²­ íšŸìˆ˜',
    registry=registry
)
PAGE_FETCH_DURATION = Histogram(
    'naver_scraper_page_fetch_duration_seconds',
    'í˜ì´ì§€ ìš”ì²­ ì§€ì—° ì‹œê°„(ì´ˆ)',
    buckets=(0.1, 0.5, 1, 2, 5, 10),
    registry=registry
)
ARTICLE_COUNTER = Counter(
    'naver_scraper_articles_processed_total',
    'ì²˜ë¦¬ëœ ë§¤ë¬¼(article) ì´ ê±´ìˆ˜',
    registry=registry
)
LAST_PAGE_ARTICLE_GAUGE = Gauge(
    'naver_scraper_last_page_article_count',
    'ë§ˆì§€ë§‰ í˜ì´ì§€ì—ì„œ ê°€ì ¸ì˜¨ ë§¤ë¬¼(article) ìˆ˜',
    registry=registry
)

# ë©”íŠ¸ë¦­ ì„œë²„ ì‹œì‘ ìƒíƒœë¥¼ ì¶”ì í•˜ëŠ” ì „ì—­ ë³€ìˆ˜
metrics_server_started = False
metrics_server_lock = threading.Lock()

def start_metrics_server():
    """Prometheus metrics ì„œë²„ ì‹œì‘ (í¬íŠ¸ 8000)"""
    global metrics_server_started
    
    with metrics_server_lock:
        if not metrics_server_started:
            try:
                start_http_server(8000, registry=registry)
                metrics_server_started = True
                print("âœ… Prometheus metrics server started on :8000")
            except Exception as e:
                print(f"âŒ Failed to start metrics server: {e}")
        else:
            print("â„¹ï¸ Metrics server already running")

def get_metric_value(metric):
    """ë©”íŠ¸ë¦­ ê°’ì„ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    try:
        if hasattr(metric, '_value'):
            if hasattr(metric._value, '_value'):
                return metric._value._value
            else:
                return metric._value
        else:
            # Counterë‚˜ Gaugeì˜ ê²½ìš° ì§ì ‘ ê°’ì„ ê°€ì ¸ì˜¬ ìˆ˜ ìˆëŠ” ë°©ë²•
            samples = list(metric.collect())[0].samples
            if samples:
                return samples[0].value
            return 0
    except Exception as e:
        print(f"ë©”íŠ¸ë¦­ ê°’ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return 0

def print_metrics_debug():
    """ë””ë²„ê¹…ì„ ìœ„í•œ ë©”íŠ¸ë¦­ ê°’ ì¶œë ¥"""
    try:
        print(f"=== ë©”íŠ¸ë¦­ ë””ë²„ê¹… ì •ë³´ ===")
        print(f"PAGE_FETCH_COUNTER: {get_metric_value(PAGE_FETCH_COUNTER)}")
        print(f"ARTICLE_COUNTER: {get_metric_value(ARTICLE_COUNTER)}")
        print(f"LAST_PAGE_ARTICLE_GAUGE: {get_metric_value(LAST_PAGE_ARTICLE_GAUGE)}")
        
        # Prometheus í˜•ì‹ìœ¼ë¡œ ë©”íŠ¸ë¦­ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
        metrics_output = generate_latest(registry).decode('utf-8')
        print("=== Prometheus ë©”íŠ¸ë¦­ ì¶œë ¥ ===")
        for line in metrics_output.split('\n'):
            if 'naver_scraper' in line and not line.startswith('#'):
                print(line)
        print("=" * 50)
    except Exception as e:
        print(f"ë©”íŠ¸ë¦­ ë””ë²„ê¹… ì¶œë ¥ ì‹¤íŒ¨: {e}")

# ë°±ê·¸ë¼ìš´ë“œì—ì„œ metrics ì„œë²„ êµ¬ë™ (í•œ ë²ˆë§Œ)
if not metrics_server_started:
    threading.Thread(target=start_metrics_server, daemon=True).start()

# â”€â”€â”€ Streamlit ì•± ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="ë„¤ì´ë²„ ë¶€ë™ì‚° ë°ì´í„° ìŠ¤í¬ë˜í¼",
    page_icon="ğŸ¢",
    layout="wide"
)

st.title("ë„¤ì´ë²„ ë¶€ë™ì‚° ë°ì´í„° ìŠ¤í¬ë˜í¼")
st.markdown("ë„¤ì´ë²„ ë¶€ë™ì‚°ì—ì„œ ë§¤ë¬¼ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.")

# ë©”íŠ¸ë¦­ ì •ë³´ í‘œì‹œ (ì‚¬ì´ë“œë°”ì—)
with st.sidebar:
    st.header("ğŸ“Š ë©”íŠ¸ë¦­ ì •ë³´")
    
    if st.button("ë©”íŠ¸ë¦­ ìƒˆë¡œê³ ì¹¨"):
        st.rerun()
    
    try:
        col1, col2 = st.columns(2)
        with col1:
            st.metric("í˜ì´ì§€ ìš”ì²­", get_metric_value(PAGE_FETCH_COUNTER))
            st.metric("ì²˜ë¦¬ëœ ë§¤ë¬¼", get_metric_value(ARTICLE_COUNTER))
        with col2:
            st.metric("ë§ˆì§€ë§‰ í˜ì´ì§€ ë§¤ë¬¼", get_metric_value(LAST_PAGE_ARTICLE_GAUGE))
    except Exception as e:
        st.error(f"ë©”íŠ¸ë¦­ í‘œì‹œ ì˜¤ë¥˜: {e}")

def fetch_real_estate_data(complex_no, page=1, max_pages=10):
    all_articles = []
    status_placeholder = st.empty()
    progress_bar = st.progress(0)

    cookies = {
        'NAC': 't9neDIhO7XOeC',
        'NACT': '1',
        'NNB': 'PABUYQL3IUEGQ',
        'SRT30': '1745372539',
        'SRT5': '1745372539',
        'page_uid': 'jsmaYql3IUEGQ',
        '_naver_usersession_': '9vysnRea1HFqlM9WDkofSQ==',
        'nhn.realestate.article.rlet_type_cd': 'A01',
        'nhn.realestate.article.trade_type_cd': '""',
        'nhn.realestate.article.ipaddress_city': '4100000000',
        '_fwb': '170rFhWLiFMt8pEQwrRRiAc.1745372608079',
        'landHomeFlashUseYn': 'Y',
        'realestate.beta.lastclick.cortar': '1100000000',
        'REALESTATE': 'Wed%20Apr%2023%202025%2010%3A43%3A32%20GMT%2B0900%20(Korean%20Standard%20Time)',
        'BUC': '5OChbI3YrWOGTT-aRWFAZ1HSNSvpNqoT0h7q2BedePg=',
    }

    headers = {
        'accept': '*/*',
        'accept-language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
        'authorization': 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IlJFQUxFU1RBVEUiLCJpYXQiOjE3NDUzNzI2MTIsImV4cCI6MTc0NTM4MzQxMn0.cAlD7MplsiOZY-Il_aocktdRiDsS77e-zN_VThjwzAo',
        'priority': 'u=1, i',
        'referer': f'https://new.land.naver.com/complexes/{complex_no}?ms=37.6099682,127.1045329,17&a=APT:PRE:ABYG:JGC:OPST&e=RETAIL',
        'sec-ch-ua': '"Google Chrome";v="135", "Not-A.Brand";v="8", "Chromium";v="135"',
        'sec-ch-ua-mobile': '?0',
        'sec-ch-ua-platform': '"Windows"',
        'sec-fetch-dest': 'empty',
        'sec-fetch-mode': 'cors',
        'sec-fetch-site': 'same-origin',
        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36',
    }

    current_page = page
    while current_page <= max_pages:
        status_placeholder.text(f"ğŸ“„ í˜ì´ì§€ {current_page}/{max_pages} ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        progress_bar.progress(current_page / max_pages)

        url = (
            f'https://new.land.naver.com/api/articles/complex/{complex_no}'
            f'?realEstateType=APT%3APRE%3AABYG%3AJGC%3AOPST&tradeType=&'
            f'tag=%3A%3A%3A%3A%3A%3A%3A%3A&rentPriceMin=0&rentPriceMax=900000000'
            f'&priceMin=0&priceMax=900000000&areaMin=0&areaMax=900000000'
            f'&oldBuildYears&recentlyBuildYears&minHouseHoldCount&maxHouseHoldCount'
            f'&showArticle=false&sameAddressGroup=false&minMaintenanceCost'
            f'&maxMaintenanceCost&priceType=RETAIL&directions=&page={current_page}'
            f'&complexNo={complex_no}&buildingNos=&areaNos=&type=list&order=rank'
        )

        # HTTP ìš”ì²­ ë° ë©”íŠ¸ë¦­ ì¸¡ì •
        request_start_time = time.time()
        
        try:
            with PAGE_FETCH_DURATION.time():
                response = requests.get(url, cookies=cookies, headers=headers)
                response.raise_for_status()
                
            # ìš”ì²­ì´ ì„±ê³µí•œ ê²½ìš°ì—ë§Œ í˜ì´ì§€ ì¹´ìš´í„° ì¦ê°€
            PAGE_FETCH_COUNTER.inc()
            print(f"âœ… í˜ì´ì§€ {current_page} ìš”ì²­ ì„±ê³µ - ì¹´ìš´í„° ì¦ê°€")
            
        except Exception as e:
            status_placeholder.error(f"âŒ í˜ì´ì§€ {current_page} ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            print(f"âŒ HTTP ìš”ì²­ ì‹¤íŒ¨: {e}")
            break

        # JSON íŒŒì‹±
        try:
            data = response.json()
            print(f"ğŸ“Š í˜ì´ì§€ {current_page} JSON íŒŒì‹± ì„±ê³µ")
        except Exception as e:
            status_placeholder.error(f"âŒ í˜ì´ì§€ {current_page} JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            continue

        # ë§¤ë¬¼ ë°ì´í„° ì²˜ë¦¬
        articles = data.get('articleList', [])
        article_count = len(articles)
        
        print(f"ğŸ“„ í˜ì´ì§€ {current_page}: {article_count}ê°œ ë§¤ë¬¼ ë°œê²¬")
        
        if not articles:
            status_placeholder.text("â„¹ï¸ ë” ì´ìƒ ë§¤ë¬¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            LAST_PAGE_ARTICLE_GAUGE.set(0)
            break

        # ë§¤ë¬¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        all_articles.extend(articles)
        
        # ë§¤ë¬¼ ì¹´ìš´í„° ì¦ê°€ (ì´ í˜ì´ì§€ì—ì„œ ê°€ì ¸ì˜¨ ë§¤ë¬¼ ìˆ˜ë§Œí¼)
        ARTICLE_COUNTER.inc(article_count)
        print(f"ğŸ“ˆ ë§¤ë¬¼ ì¹´ìš´í„° {article_count}ê°œ ì¦ê°€")
        
        # ê²Œì´ì§€ ì—…ë°ì´íŠ¸ (ë§ˆì§€ë§‰ í˜ì´ì§€ì˜ ë§¤ë¬¼ ìˆ˜)
        LAST_PAGE_ARTICLE_GAUGE.set(article_count)
        print(f"ğŸ“Š ê²Œì´ì§€ë¥¼ {article_count}ë¡œ ì„¤ì •")
        
        # ë©”íŠ¸ë¦­ ë””ë²„ê¹… ì¶œë ¥
        print_metrics_debug()

        status_placeholder.text(f"âœ… í˜ì´ì§€ {current_page}ì—ì„œ {article_count}ê°œ ë§¤ë¬¼ ì •ë³´ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
        
        # ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
        if not data.get('isMoreData', False):
            status_placeholder.text("âœ… ë§ˆì§€ë§‰ í˜ì´ì§€ì…ë‹ˆë‹¤.")
            break

        time.sleep(1)  # ìš”ì²­ ê°„ ë”œë ˆì´
        current_page += 1

    progress_bar.progress(1.0)
    total_articles = len(all_articles)
    status_placeholder.text(f"ğŸ‰ ì´ {total_articles}ê°œ ë§¤ë¬¼ ì •ë³´ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
    
    # ìµœì¢… ë©”íŠ¸ë¦­ ë””ë²„ê¹… ì •ë³´
    print(f"\n{'='*50}")
    print(f"ğŸ¯ ìµœì¢… ê²°ê³¼")
    print(f"{'='*50}")
    print(f"ì‹¤ì œ ìˆ˜ì§‘ëœ ë§¤ë¬¼ ìˆ˜: {total_articles}")
    print(f"ì²˜ë¦¬í•œ í˜ì´ì§€ ìˆ˜: {current_page - 1}")
    print_metrics_debug()
    
    return all_articles

def clean_price(price_str):
    if not price_str:
        return ""
    price_str = price_str.replace("ì–µ", " ").strip()
    parts = price_str.split()
    if len(parts) == 2:
        try:
            billions = float(parts[0])
            thousands = float(parts[1].replace(",", "")) / 10000
            return f"{billions + thousands:.2f}"
        except (ValueError, IndexError):
            return price_str
    try:
        return f"{float(price_str):.2f}"
    except ValueError:
        return price_str

def process_data(articles):
    if not articles:
        return pd.DataFrame()
    processed_data = []
    for article in articles:
        processed_data.append({
            'ë§¤ë¬¼ë²ˆí˜¸': article.get('articleNo', ''),
            'ë§¤ë¬¼ëª…': article.get('articleName', ''),
            'ê±´ë¬¼ëª…': article.get('buildingName', ''),
            'ê±°ë˜ìœ í˜•': article.get('tradeTypeName', ''),
            'ê°€ê²©': article.get('dealOrWarrantPrc', ''),
            'ê°€ê²©(ì–µ)': clean_price(article.get('dealOrWarrantPrc', '')),
            'ë©´ì ëª…': article.get('areaName', ''),
            'ê³µê¸‰ë©´ì (ã¡)': article.get('area1', ''),
            'ì „ìš©ë©´ì (ã¡)': article.get('area2', ''),
            'ì¸µì •ë³´': article.get('floorInfo', ''),
            'ë°©í–¥': article.get('direction', ''),
            'íƒœê·¸': ', '.join(article.get('tagList', [])) if isinstance(article.get('tagList'), list) else article.get('tagList', ''),
            'íŠ¹ì§•': article.get('articleFeatureDesc', ''),
            'ë¶€ë™ì‚°': article.get('realtorName', ''),
            'í™•ì¸ì¼ì': article.get('articleConfirmYmd', ''),
            'ìœ„ë„': article.get('latitude', ''),
            'ê²½ë„': article.get('longitude', '')
        })
    df = pd.DataFrame(processed_data)
    df['ê°€ê²©(ì–µ)'] = pd.to_numeric(df['ê°€ê²©(ì–µ)'], errors='coerce')
    return df

def create_download_link(df, filename="data.csv"):
    csv_data = df.to_csv(index=False, encoding='utf-8-sig')
    b64 = base64.b64encode(csv_data.encode('utf-8-sig')).decode()
    return f'<a href="data:file/csv;base64,{b64}" download="{filename}">ğŸ“¥ CSV íŒŒì¼ ë‹¤ìš´ë¡œë“œ</a>'

def main():
    # ë©”íŠ¸ë¦­ ì„œë²„ê°€ ì‹œì‘ë˜ì—ˆëŠ”ì§€ í™•ì¸
    start_metrics_server()
    
    st.sidebar.header("ğŸ”§ ê²€ìƒ‰ ì„¤ì •")
    complex_no = st.sidebar.text_input(
        "ë‹¨ì§€ ë²ˆí˜¸ ì…ë ¥",
        value="131345",
        help="ë„¤ì´ë²„ ë¶€ë™ì‚° URLì—ì„œ complexes/ ë‹¤ìŒì— ì˜¤ëŠ” ìˆ«ìì…ë‹ˆë‹¤."
    )
    max_pages = st.sidebar.slider(
        "ìµœëŒ€ í˜ì´ì§€ ìˆ˜",
        min_value=1,
        max_value=20,
        value=5,
        help="ê°€ì ¸ì˜¬ ìµœëŒ€ í˜ì´ì§€ ìˆ˜"
    )

    if st.sidebar.button("ğŸš€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°", type="primary"):
        try:
            cn = int(complex_no)
        except ValueError:
            st.error("âŒ ë‹¨ì§€ ë²ˆí˜¸ëŠ” ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤.")
            return

        with st.spinner("ğŸ”„ ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
            articles = fetch_real_estate_data(cn, max_pages=max_pages)
            if not articles:
                st.warning("âš ï¸ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return
            df = process_data(articles)
            st.session_state.df = df
            st.session_state.cn = cn
            st.success(f"ğŸ‰ ì´ {len(df)} ê°œì˜ ë§¤ë¬¼ ì •ë³´ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤!")
            
            # ë©”íŠ¸ë¦­ ì •ë³´ ìë™ ìƒˆë¡œê³ ì¹¨
            st.rerun()

    if 'df' in st.session_state and not st.session_state.df.empty:
        df = st.session_state.df
        cn = st.session_state.cn
        tab1, tab2, tab3 = st.tabs(["ğŸ“„ ë°ì´í„°", "ğŸ“Š ë¶„ì„", "ğŸ“ˆ ì‹œê°í™”"])

        with tab1:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"naver_real_estate_data_{cn}_{timestamp}.csv"
            st.markdown(create_download_link(df, filename), unsafe_allow_html=True)
            st.dataframe(df, use_container_width=True)

        with tab2:
            st.subheader("ğŸ“Š ë°ì´í„° ë¶„ì„")
            if 'ê°€ê²©(ì–µ)' in df.columns:
                c1, c2, c3 = st.columns(3)
                c1.metric("í‰ê·  ê°€ê²©(ì–µ)", f"{df['ê°€ê²©(ì–µ)'].mean():.2f}")
                c2.metric("ìµœê³  ê°€ê²©(ì–µ)", f"{df['ê°€ê²©(ì–µ)'].max():.2f}")
                c3.metric("ìµœì € ê°€ê²©(ì–µ)", f"{df['ê°€ê²©(ì–µ)'].min():.2f}")

            st.subheader("ê±°ë˜ ìœ í˜•ë³„ í‰ê·  ê°€ê²©")
            if 'ê±°ë˜ìœ í˜•' in df.columns:
                trade_avg = df.groupby('ê±°ë˜ìœ í˜•')['ê°€ê²©(ì–µ)'].agg(['mean','count']).reset_index()
                trade_avg.columns = ['ê±°ë˜ìœ í˜•','í‰ê·  ê°€ê²©(ì–µ)','ë§¤ë¬¼ ìˆ˜']
                st.dataframe(trade_avg, use_container_width=True)

            st.subheader("ë©´ì ë³„ í‰ê·  ê°€ê²©")
            if 'ì „ìš©ë©´ì (ã¡)' in df.columns:
                df['ë©´ì êµ¬ê°„'] = pd.cut(df['ì „ìš©ë©´ì (ã¡)'], bins=[0,30,60,85,120,200],
                                      labels=['~30ã¡','30~60ã¡','60~85ã¡','85~120ã¡','120ã¡~'])
                area_avg = df.groupby('ë©´ì êµ¬ê°„')['ê°€ê²©(ì–µ)'].agg(['mean','count']).reset_index()
                area_avg.columns=['ë©´ì êµ¬ê°„','í‰ê·  ê°€ê²©(ì–µ)','ë§¤ë¬¼ ìˆ˜']
                st.dataframe(area_avg, use_container_width=True)

        with tab3:
            st.subheader("ğŸ“ˆ ë°ì´í„° ì‹œê°í™”")
            if 'ê°€ê²©(ì–µ)' in df.columns:
                st.subheader("ê°€ê²© ë¶„í¬")
                fig = px.histogram(df, x='ê°€ê²©(ì–µ)', nbins=20, title="ê°€ê²© ë¶„í¬")
                st.plotly_chart(fig, use_container_width=True)

                if 'ì¸µì •ë³´' in df.columns:
                    df['ì¸µ'] = df['ì¸µì •ë³´'].str.extract(r'(\d+)/').astype(float, errors='ignore')
                    fl = df.dropna(subset=['ì¸µ'])
                    if not fl.empty:
                        st.subheader("ì¸µë³„ ê°€ê²©")
                        fig = px.scatter(fl, x='ì¸µ', y='ê°€ê²©(ì–µ)',
                                         color='ê±°ë˜ìœ í˜•' if 'ê±°ë˜ìœ í˜•' in fl.columns else None,
                                         title="ì¸µë³„ ê°€ê²©",
                                         labels={'ì¸µ':'ì¸µ','ê°€ê²©(ì–µ)':'ê°€ê²©(ì–µ)'})
                        st.plotly_chart(fig, use_container_width=True)

                if 'ì „ìš©ë©´ì (ã¡)' in df.columns:
                    st.subheader("ë©´ì ë³„ ê°€ê²©")
                    fig = px.scatter(df, x='ì „ìš©ë©´ì (ã¡)', y='ê°€ê²©(ì–µ)',
                                     color='ê±°ë˜ìœ í˜•' if 'ê±°ë˜ìœ í˜•' in df.columns else None,
                                     title="ë©´ì ë³„ ê°€ê²©",
                                     labels={'ì „ìš©ë©´ì (ã¡)':'ì „ìš©ë©´ì (ã¡)','ê°€ê²©(ì–µ)':'ê°€ê²©(ì–µ)'})
                    st.plotly_chart(fig, use_container_width=True)

                if 'ìœ„ë„' in df.columns and 'ê²½ë„' in df.columns:
                    st.subheader("ğŸ—ºï¸ ì§€ë„ ë³´ê¸°")
                    df['ìœ„ë„'] = pd.to_numeric(df['ìœ„ë„'], errors='coerce')
                    df['ê²½ë„'] = pd.to_numeric(df['ê²½ë„'], errors='coerce')
                    mp = df.dropna(subset=['ìœ„ë„','ê²½ë„'])
                    if not mp.empty:
                        fig = px.scatter_mapbox(mp, lat='ìœ„ë„', lon='ê²½ë„',
                                               color='ê°€ê²©(ì–µ)',
                                               size='ì „ìš©ë©´ì (ã¡)' if 'ì „ìš©ë©´ì (ã¡)' in mp.columns else None,
                                               hover_name='ë§¤ë¬¼ëª…',
                                               hover_data=['ê°€ê²©','ê±°ë˜ìœ í˜•','ì¸µì •ë³´','ì „ìš©ë©´ì (ã¡)'],
                                               zoom=15,
                                               mapbox_style="carto-positron")
                        st.plotly_chart(fig, use_container_width=True)

if __name__ == "__main__":
    main()

import streamlit as st
import requests
import json
import csv
import time
import pandas as pd
import base64
from datetime import datetime
import plotly.express as px
import io

# Set page config
st.set_page_config(
    page_title="ë„¤ì´ë²„ ë¶€ë™ì‚° ë°ì´í„° ìŠ¤í¬ë˜í¼",
    page_icon="ğŸ¢",
    layout="wide"
)

# Title and description
st.title("ë„¤ì´ë²„ ë¶€ë™ì‚° ë°ì´í„° ìŠ¤í¬ë˜í¼")
st.markdown("ë„¤ì´ë²„ ë¶€ë™ì‚°ì—ì„œ ë§¤ë¬¼ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.")

def fetch_real_estate_data(complex_no, page=1, max_pages=10):
    """
    Fetch real estate listing data from Naver Land API
    
    Args:
        complex_no (int): The complex number to fetch data for
        page (int): Starting page number
        max_pages (int): Maximum number of pages to fetch
        
    Returns:
        list: List of real estate listings
    """
    all_articles = []
    
    # Status placeholder for progress updates
    status_placeholder = st.empty()
    progress_bar = st.progress(0)
    
    # Set up the cookies and headers for the request
    cookies = {
        'NAC': 't9neDIhO7XOeC',
        'NACT': '1',
        'NNB': 'PABUYQL3IUEGQ',
        'SRT30': '1745372539',
        'SRT5': '1745372539',
        'page_uid': 'jsmaYlqpsECssZM5/xhssssssCG-013955',
        '_naver_usersession_': '9vysnRea1HFqlM9WDkofSQ==',
        'nhn.realestate.article.rlet_type_cd': 'A01',
        'nhn.realestate.article.trade_type_cd': '""',
        'nhn.realestate.article.ipaddress_city': '4100000000',
        '_fwb': '170rFhWLiFMt8pEQwrRRiAc.1745372608079',
        'landHomeFlashUseYn': 'Y',
        'realestate.beta.lastclick.cortar': '1100000000',
        'REALESTATE': 'Wed%20Apr%2023%202025%2010%3A43%3A32%20GMT%2B0900%20(Korean%20Standard%20Time)',
        'BUC': '5OChbI3YrWOGTT-aRWFAZ1HSNSvpNqoT0h7q2BedePg=',
    }

    headers = {
        'accept': '*/*',
        'accept-language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
        'authorization': 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IlJFQUxFU1RBVEUiLCJpYXQiOjE3NDUzNzI2MTIsImV4cCI6MTc0NTM4MzQxMn0.cAlD7MplsiOZY-Il_aocktdRiDsS77e-zN_VThjwzAo',
        'priority': 'u=1, i',
        'referer': f'https://new.land.naver.com/complexes/{complex_no}?ms=37.6099682,127.1045329,17&a=APT:PRE:ABYG:JGC:OPST&e=RETAIL',
        'sec-ch-ua': '"Google Chrome";v="135", "Not-A.Brand";v="8", "Chromium";v="135"',
        'sec-ch-ua-mobile': '?0',
        'sec-ch-ua-platform': '"Windows"',
        'sec-fetch-dest': 'empty',
        'sec-fetch-mode': 'cors',
        'sec-fetch-site': 'same-origin',
        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36',
    }
    
    # Fetch data from multiple pages
    current_page = page
    while current_page <= max_pages:
        status_placeholder.text(f"í˜ì´ì§€ {current_page}/{max_pages} ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        progress_bar.progress(current_page / max_pages)
        
        url = f'https://new.land.naver.com/api/articles/complex/{complex_no}?realEstateType=APT%3APRE%3AABYG%3AJGC%3AOPST&tradeType=&tag=%3A%3A%3A%3A%3A%3A%3A%3A&rentPriceMin=0&rentPriceMax=900000000&priceMin=0&priceMax=900000000&areaMin=0&areaMax=900000000&oldBuildYears&recentlyBuildYears&minHouseHoldCount&maxHouseHoldCount&showArticle=false&sameAddressGroup=false&minMaintenanceCost&maxMaintenanceCost&priceType=RETAIL&directions=&page={current_page}&complexNo={complex_no}&buildingNos=&areaNos=&type=list&order=rank'
        
        try:
            response = requests.get(url, cookies=cookies, headers=headers)
            response.raise_for_status()  # Raise exception for HTTP errors
            
            data = response.json()
            
            # Check if we have reached the end of the data
            if 'articleList' not in data or not data['articleList']:
                status_placeholder.text(f"í˜ì´ì§€ {current_page}ì—ì„œ ë” ì´ìƒ ë§¤ë¬¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                break
                
            articles = data['articleList']
            all_articles.extend(articles)
            
            status_placeholder.text(f"í˜ì´ì§€ {current_page}ì—ì„œ {len(articles)}ê°œ ë§¤ë¬¼ ì •ë³´ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
            
            # Check if more data is available
            if not data.get('isMoreData', False):
                status_placeholder.text("ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                break
                
            # Sleep to avoid hitting rate limits
            time.sleep(1)
            current_page += 1
            
        except requests.exceptions.RequestException as e:
            status_placeholder.error(f"í˜ì´ì§€ {current_page} ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            break
        except json.JSONDecodeError as e:
            status_placeholder.error(f"í˜ì´ì§€ {current_page} JSON ë””ì½”ë”© ì‹¤íŒ¨: {e}")
            break
    
    progress_bar.progress(1.0)
    status_placeholder.text(f"ì´ {len(all_articles)}ê°œ ë§¤ë¬¼ ì •ë³´ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
    
    return all_articles

def clean_price(price_str):
    """
    Clean and standardize Korean real estate price strings
    Examples:
    - "5ì–µ" -> "5.00" (5ì–µ ì›, or 500 million won)
    - "5ì–µ 2,000" -> "5.20" (5ì–µ 2ì²œë§Œ ì›, or 520 million won)
    """
    if not price_str:
        return ""
    
    # Replace the Korean "ì–µ" unit with a space so both "5ì–µ 2,000" and
    # "5ì–µ2,000" formats are handled consistently
    price_str = price_str.replace("ì–µ", " ").strip()
    
    # Handle price formats like "5ì–µ 2,000"
    parts = price_str.split()
    if len(parts) == 2:
        try:
            billions = float(parts[0])
            # In Korean real estate, the second part is already in units of 10,000 won (ë§Œ ì›)
            # So for "5ì–µ 2,000", the 2,000 means 2,000ë§Œ ì› (20 million won)
            thousands = float(parts[1].replace(",", "")) / 10000
            return f"{billions + thousands:.2f}"
        except (ValueError, IndexError):
            return price_str
    
    try:
        return f"{float(price_str):.2f}"
    except ValueError:
        return price_str

def process_data(articles):
    """Process the raw articles into a pandas DataFrame"""
    if not articles:
        return pd.DataFrame()
    
    # Create a list to store processed data
    processed_data = []
    
    for article in articles:
        # Extract relevant fields
        row = {
            'ë§¤ë¬¼ë²ˆí˜¸': article.get('articleNo', ''),
            'ë§¤ë¬¼ëª…': article.get('articleName', ''),
            'ê±´ë¬¼ëª…': article.get('buildingName', ''),
            'ê±°ë˜ìœ í˜•': article.get('tradeTypeName', ''),
            'ê°€ê²©': article.get('dealOrWarrantPrc', ''),
            'ê°€ê²©(ì–µ)': clean_price(article.get('dealOrWarrantPrc', '')),
            'ë©´ì ëª…': article.get('areaName', ''),
            'ê³µê¸‰ë©´ì (ã¡)': article.get('area1', ''),
            'ì „ìš©ë©´ì (ã¡)': article.get('area2', ''),
            'ì¸µì •ë³´': article.get('floorInfo', ''),
            'ë°©í–¥': article.get('direction', ''),
            'íƒœê·¸': ', '.join(article.get('tagList', [])) if isinstance(article.get('tagList'), list) else article.get('tagList', ''),
            'íŠ¹ì§•': article.get('articleFeatureDesc', ''),
            'ë¶€ë™ì‚°': article.get('realtorName', ''),
            'í™•ì¸ì¼ì': article.get('articleConfirmYmd', ''),
            'ìœ„ë„': article.get('latitude', ''),
            'ê²½ë„': article.get('longitude', '')
        }
        processed_data.append(row)
    
    # Convert to DataFrame
    df = pd.DataFrame(processed_data)
    
    # Convert price to numeric for analysis
    df['ê°€ê²©(ì–µ)'] = pd.to_numeric(df['ê°€ê²©(ì–µ)'], errors='coerce')
    
    return df

def create_download_link(df, filename="data.csv"):
    """Generate a download link for the dataframe"""
    csv = df.to_csv(index=False, encoding='utf-8-sig')
    b64 = base64.b64encode(csv.encode('utf-8-sig')).decode()
    href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">CSV íŒŒì¼ ë‹¤ìš´ë¡œë“œ</a>'
    return href

def main():
    # Sidebar inputs
    st.sidebar.header("ê²€ìƒ‰ ì„¤ì •")
    
    # Complex number input
    complex_no = st.sidebar.text_input(
        "ë‹¨ì§€ ë²ˆí˜¸ ì…ë ¥",
        value="131345",
        help="ë„¤ì´ë²„ ë¶€ë™ì‚° URLì—ì„œ complexes/ ë‹¤ìŒì— ì˜¤ëŠ” ìˆ«ìì…ë‹ˆë‹¤. ì˜ˆ: https://new.land.naver.com/complexes/131345"
    )
    
    # Max pages input
    max_pages = st.sidebar.slider(
        "ìµœëŒ€ í˜ì´ì§€ ìˆ˜",
        min_value=1,
        max_value=20,
        value=5,
        help="ê°€ì ¸ì˜¬ ìµœëŒ€ í˜ì´ì§€ ìˆ˜"
    )
    
    # Fetch data button
    if st.sidebar.button("ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"):
        if not complex_no:
            st.error("ë‹¨ì§€ ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
            
        try:
            complex_no = int(complex_no)
        except ValueError:
            st.error("ë‹¨ì§€ ë²ˆí˜¸ëŠ” ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤.")
            return
            
        # Fetch data
        with st.spinner("ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
            articles = fetch_real_estate_data(complex_no, max_pages=max_pages)
            
            if not articles:
                st.warning("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return
                
            # Process data
            df = process_data(articles)
            
            # Store in session state
            st.session_state.df = df
            st.session_state.complex_no = complex_no
            
            # Success message
            st.success(f"ì´ {len(df)} ê°œì˜ ë§¤ë¬¼ ì •ë³´ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤!")
    
    # Display data if available
    if 'df' in st.session_state and not st.session_state.df.empty:
        df = st.session_state.df
        complex_no = st.session_state.complex_no
        
        # Create tabs
        tab1, tab2, tab3 = st.tabs(["ë°ì´í„°", "ë¶„ì„", "ì‹œê°í™”"])
        
        with tab1:
            # Download button
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"naver_real_estate_data_{complex_no}_{timestamp}.csv"
            st.markdown(create_download_link(df, filename), unsafe_allow_html=True)
            
            # Display dataframe
            st.dataframe(df, use_container_width=True)
        
        with tab2:
            st.subheader("ë°ì´í„° ë¶„ì„")
            
            # Basic statistics
            if 'ê°€ê²©(ì–µ)' in df.columns:
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("í‰ê·  ê°€ê²©(ì–µ)", f"{df['ê°€ê²©(ì–µ)'].mean():.2f}")
                
                with col2:
                    st.metric("ìµœê³  ê°€ê²©(ì–µ)", f"{df['ê°€ê²©(ì–µ)'].max():.2f}")
                
                with col3:
                    st.metric("ìµœì € ê°€ê²©(ì–µ)", f"{df['ê°€ê²©(ì–µ)'].min():.2f}")
            
            # Group by analysis
            st.subheader("ê±°ë˜ ìœ í˜•ë³„ í‰ê·  ê°€ê²©")
            if 'ê±°ë˜ìœ í˜•' in df.columns and 'ê°€ê²©(ì–µ)' in df.columns:
                trade_type_avg = df.groupby('ê±°ë˜ìœ í˜•')['ê°€ê²©(ì–µ)'].agg(['mean', 'count']).reset_index()
                trade_type_avg.columns = ['ê±°ë˜ìœ í˜•', 'í‰ê·  ê°€ê²©(ì–µ)', 'ë§¤ë¬¼ ìˆ˜']
                st.dataframe(trade_type_avg, use_container_width=True)
            
            st.subheader("ë©´ì ë³„ í‰ê·  ê°€ê²©")
            if 'ì „ìš©ë©´ì (ã¡)' in df.columns and 'ê°€ê²©(ì–µ)' in df.columns:
                # Create bins for area
                df['ë©´ì êµ¬ê°„'] = pd.cut(
                    df['ì „ìš©ë©´ì (ã¡)'], 
                    bins=[0, 30, 60, 85, 120, 200],
                    labels=['~30ã¡', '30~60ã¡', '60~85ã¡', '85~120ã¡', '120ã¡~']
                )
                
                area_avg = df.groupby('ë©´ì êµ¬ê°„')['ê°€ê²©(ì–µ)'].agg(['mean', 'count']).reset_index()
                area_avg.columns = ['ë©´ì êµ¬ê°„', 'í‰ê·  ê°€ê²©(ì–µ)', 'ë§¤ë¬¼ ìˆ˜']
                st.dataframe(area_avg, use_container_width=True)
        
        with tab3:
            st.subheader("ë°ì´í„° ì‹œê°í™”")
            
            if 'ê°€ê²©(ì–µ)' in df.columns:
                # Price distribution
                st.subheader("ê°€ê²© ë¶„í¬")
                fig = px.histogram(df, x='ê°€ê²©(ì–µ)', nbins=20, title="ê°€ê²© ë¶„í¬")
                st.plotly_chart(fig, use_container_width=True)
                
                # Price by floor
                if 'ì¸µì •ë³´' in df.columns:
                    # Extract floor number
                    df['ì¸µ'] = df['ì¸µì •ë³´'].str.extract(r'(\d+)/')
                    df['ì¸µ'] = pd.to_numeric(df['ì¸µ'], errors='coerce')
                    
                    # Filter out rows with missing floor
                    floor_df = df.dropna(subset=['ì¸µ'])
                    
                    if not floor_df.empty:
                        st.subheader("ì¸µë³„ ê°€ê²©")
                        fig = px.scatter(
                            floor_df, 
                            x='ì¸µ', 
                            y='ê°€ê²©(ì–µ)',
                            color='ê±°ë˜ìœ í˜•' if 'ê±°ë˜ìœ í˜•' in floor_df.columns else None,
                            title="ì¸µë³„ ê°€ê²©",
                            labels={'ì¸µ': 'ì¸µ', 'ê°€ê²©(ì–µ)': 'ê°€ê²©(ì–µ)'}
                        )
                        st.plotly_chart(fig, use_container_width=True)
                
                # Price by area
                if 'ì „ìš©ë©´ì (ã¡)' in df.columns:
                    st.subheader("ë©´ì ë³„ ê°€ê²©")
                    fig = px.scatter(
                        df, 
                        x='ì „ìš©ë©´ì (ã¡)', 
                        y='ê°€ê²©(ì–µ)',
                        color='ê±°ë˜ìœ í˜•' if 'ê±°ë˜ìœ í˜•' in df.columns else None,
                        title="ë©´ì ë³„ ê°€ê²©",
                        labels={'ì „ìš©ë©´ì (ã¡)': 'ì „ìš©ë©´ì (ã¡)', 'ê°€ê²©(ì–µ)': 'ê°€ê²©(ì–µ)'}
                    )
                    st.plotly_chart(fig, use_container_width=True)
                
                # Map view
                if 'ìœ„ë„' in df.columns and 'ê²½ë„' in df.columns:
                    st.subheader("ì§€ë„ ë³´ê¸°")
                    
                    # Convert lat/lon to numeric
                    df['ìœ„ë„'] = pd.to_numeric(df['ìœ„ë„'], errors='coerce')
                    df['ê²½ë„'] = pd.to_numeric(df['ê²½ë„'], errors='coerce')
                    
                    # Filter out rows with missing coordinates
                    map_df = df.dropna(subset=['ìœ„ë„', 'ê²½ë„'])
                    
                    if not map_df.empty:
                        fig = px.scatter_mapbox(
                            map_df,
                            lat='ìœ„ë„',
                            lon='ê²½ë„',
                            color='ê°€ê²©(ì–µ)',
                            size='ì „ìš©ë©´ì (ã¡)' if 'ì „ìš©ë©´ì (ã¡)' in map_df.columns else None,
                            hover_name='ë§¤ë¬¼ëª…',
                            hover_data=['ê°€ê²©', 'ê±°ë˜ìœ í˜•', 'ì¸µì •ë³´', 'ì „ìš©ë©´ì (ã¡)'],
                            color_continuous_scale=px.colors.sequential.Plasma,
                            zoom=15,
                            mapbox_style="carto-positron"
                        )
                        st.plotly_chart(fig, use_container_width=True)

if __name__ == "__main__":
    main()
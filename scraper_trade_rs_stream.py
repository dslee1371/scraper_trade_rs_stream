import time
import streamlit as st
import requests
import json
import csv
import pandas as pd
import base64
from datetime import datetime
import plotly.express as px
import io

# Prometheus client imports
from prometheus_client import Counter, Histogram, generate_latest, CONTENT_TYPE_LATEST
from flask import Flask, Response
from threading import Thread

# â”€â”€â”€ Prometheus ë©”íŠ¸ë¦­ ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PAGE_VIEWS = Counter(
    'streamlit_page_views_total',
    'Total number of times the Streamlit app was loaded'
)
FETCH_CALLS = Counter(
    'naver_fetch_calls_total',
    'Total number of calls to fetch_real_estate_data'
)
FETCH_LATENCY = Histogram(
    'naver_fetch_latency_seconds',
    'Latency of each fetch_real_estate_data call in seconds',
    buckets=[0.5, 1, 2, 5, 10]
)

# â”€â”€â”€ Flask ì„œë²„ë¡œ /metrics ì—”ë“œí¬ì¸íŠ¸ ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
flask_app = Flask(__name__)

@flask_app.route("/metrics")
def metrics():
    return Response(generate_latest(), mimetype=CONTENT_TYPE_LATEST)

def run_metrics_server():
    flask_app.run(host="0.0.0.0", port=8001)

Thread(target=run_metrics_server, daemon=True).start()

# â”€â”€â”€ Streamlit í˜ì´ì§€ ë¡œë“œ ì‹œ ë©”íŠ¸ë¦­ ì¦ê°€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PAGE_VIEWS.inc()

# â”€â”€â”€ ë°ì´í„° ìŠ¤í¬ë˜í•‘ í•¨ìˆ˜ (ë©”íŠ¸ë¦­ í¬í•¨) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_real_estate_data(complex_no, page=1, max_pages=10):
    FETCH_CALLS.inc()
    start_time = time.time()

    all_articles = []
    status_placeholder = st.empty()
    progress_bar = st.progress(0.0)

    cookies = {
        'NAC': 't9neDIhO7XOeC',
        'NACT': '1',
        'NNB': 'PABUYQL3IUEGQ',
        'SRT30': '1745372539',
        'SRT5': '1745372539',
        'page_uid': 'jsmaYlqpsECssZM5/xhssssssCG-013955',
        '_naver_usersession_': '9vysnRea1HFqlM9WDkofSQ==',
        'nhn.realestate.article.rlet_type_cd': 'A01',
        'nhn.realestate.article.trade_type_cd': '""',
        'nhn.realestate.article.ipaddress_city': '4100000000',
        '_fwb': '170rFhWLiFMt8pEQwrRRiAc.1745372608079',
        'landHomeFlashUseYn': 'Y',
        'realestate.beta.lastclick.cortar': '1100000000',
        'REALESTATE': 'Wed%20Apr%2023%202025%2010%3A43%3A32%20GMT%2B0900%20(Korean%20Standard%20Time)',
        'BUC': '5OChbI3YrWOGTT-aRWFAZ1HSNSvpNqoT0h7q2BedePg=',
    }

    headers = {
        'accept': '*/*',
        'accept-language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
        'authorization': 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IlJFQUxFU1RBVEUiLCJpYXQiOjE3NDUzNzI2MTIsImV4cCI6MTc0NTM4MzQxMn0.cAlD7MplsiOZY-Il_aocktdRiDsS77e-zN_VThjwzAo',
        'priority': 'u=1, i',
        'referer': f'https://new.land.naver.com/complexes/{complex_no}?ms=37.6099682,127.1045329,17&a=APT:PRE:ABYG:JGC:OPST&e=RETAIL',
        'sec-ch-ua': '"Google Chrome";v="135", "Not-A.Brand";v="8", "Chromium";v="135"',
        'sec-ch-ua-mobile': '?0',
        'sec-ch-ua-platform': '"Windows"',
        'sec-fetch-dest': 'empty',
        'sec-fetch-mode': 'cors',
        'sec-fetch-site': 'same-origin',
        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36',
    }

    current_page = page
    while current_page <= max_pages:
        status_placeholder.text(f"í˜ì´ì§€ {current_page}/{max_pages} ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        progress_bar.progress(current_page / max_pages)

        url = (
            f'https://new.land.naver.com/api/articles/complex/{complex_no}'
            f'?realEstateType=APT%3APRE%3AABYG%3AJGC%3AOPST&tradeType=&'
            f'tag=%3A%3A%3A%3A%3A%3A%3A%3A&rentPriceMin=0&rentPriceMax=900000000'
            f'&priceMin=0&priceMax=900000000&areaMin=0&areaMax=900000000'
            f'&oldBuildYears&recentlyBuildYears&minHouseHoldCount&maxHouseHoldCount'
            f'&showArticle=false&sameAddressGroup=false&minMaintenanceCost'
            f'&maxMaintenanceCost&priceType=RETAIL&directions='
            f'&page={current_page}&complexNo={complex_no}&buildingNos='
            f'&areaNos=&type=list&order=rank'
        )

        try:
            resp = requests.get(url, cookies=cookies, headers=headers)
            resp.raise_for_status()
            data = resp.json()

            articles = data.get('articleList', [])
            if not articles:
                status_placeholder.text("ë” ì´ìƒ ë§¤ë¬¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                break

            all_articles.extend(articles)
            if not data.get('isMoreData', False):
                status_placeholder.text("ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                break

            time.sleep(1)
            current_page += 1

        except requests.exceptions.RequestException as e:
            status_placeholder.error(f"í˜ì´ì§€ {current_page} ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            break
        except json.JSONDecodeError as e:
            status_placeholder.error(f"í˜ì´ì§€ {current_page} JSON ë””ì½”ë”© ì‹¤íŒ¨: {e}")
            break

    progress_bar.progress(1.0)
    status_placeholder.text(f"ì´ {len(all_articles)}ê°œ ë§¤ë¬¼ ì •ë³´ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")

    FETCH_LATENCY.observe(time.time() - start_time)
    return all_articles

# â”€â”€â”€ ê°€ê²© ë¬¸ìì—´ ì •ì œ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def clean_price(price_str):
    if not price_str:
        return ""
    price_str = price_str.replace("ì–µ", "").strip()
    parts = price_str.split()
    if len(parts) == 2:
        try:
            billions = float(parts[0])
            thousands = float(parts[1].replace(",", "")) / 10000
            return f"{billions + thousands:.2f}"
        except Exception:
            return price_str
    try:
        return f"{float(price_str):.2f}"
    except ValueError:
        return price_str

# â”€â”€â”€ ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def process_data(articles):
    if not articles:
        return pd.DataFrame()
    processed = []
    for art in articles:
        row = {
            'ë§¤ë¬¼ë²ˆí˜¸': art.get('articleNo', ''),
            'ë§¤ë¬¼ëª…': art.get('articleName', ''),
            'ê±´ë¬¼ëª…': art.get('buildingName', ''),
            'ê±°ë˜ìœ í˜•': art.get('tradeTypeName', ''),
            'ê°€ê²©': art.get('dealOrWarrantPrc', ''),
            'ê°€ê²©(ì–µ)': clean_price(art.get('dealOrWarrantPrc', '')),
            'ë©´ì ëª…': art.get('areaName', ''),
            'ê³µê¸‰ë©´ì (ã¡)': art.get('area1', ''),
            'ì „ìš©ë©´ì (ã¡)': art.get('area2', ''),
            'ì¸µì •ë³´': art.get('floorInfo', ''),
            'ë°©í–¥': art.get('direction', ''),
            'íƒœê·¸': ', '.join(art.get('tagList', [])) if isinstance(art.get('tagList'), list) else art.get('tagList', ''),
            'íŠ¹ì§•': art.get('articleFeatureDesc', ''),
            'ë¶€ë™ì‚°': art.get('realtorName', ''),
            'í™•ì¸ì¼ì': art.get('articleConfirmYmd', ''),
            'ìœ„ë„': art.get('latitude', ''),
            'ê²½ë„': art.get('longitude', '')
        }
        processed.append(row)
    df = pd.DataFrame(processed)
    df['ê°€ê²©(ì–µ)'] = pd.to_numeric(df['ê°€ê²©(ì–µ)'], errors='coerce')
    return df

# â”€â”€â”€ CSV ë‹¤ìš´ë¡œë“œ ë§í¬ ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def create_download_link(df, filename="data.csv"):
    csv = df.to_csv(index=False, encoding='utf-8-sig')
    b64 = base64.b64encode(csv.encode('utf-8-sig')).decode()
    href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">CSV íŒŒì¼ ë‹¤ìš´ë¡œë“œ</a>'
    return href

# â”€â”€â”€ Streamlit ë©”ì¸ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    st.set_page_config(
        page_title="ë„¤ì´ë²„ ë¶€ë™ì‚° ë°ì´í„° ìŠ¤í¬ë˜í¼",
        page_icon="ğŸ¢",
        layout="wide"
    )
    st.title("ë„¤ì´ë²„ ë¶€ë™ì‚° ë°ì´í„° ìŠ¤í¬ë˜í¼")
    st.markdown("ë„¤ì´ë²„ ë¶€ë™ì‚°ì—ì„œ ë§¤ë¬¼ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.")

    st.sidebar.header("ê²€ìƒ‰ ì„¤ì •")
    complex_no = st.sidebar.text_input(
        "ë‹¨ì§€ ë²ˆí˜¸ ì…ë ¥",
        value="131345",
        help="ì˜ˆ: https://new.land.naver.com/complexes/131345 ì—ì„œ 131345"
    )
    max_pages = st.sidebar.slider(
        "ìµœëŒ€ í˜ì´ì§€ ìˆ˜",
        min_value=1,
        max_value=20,
        value=5
    )

    if st.sidebar.button("ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"):
        if not complex_no.isdigit():
            st.error("ë‹¨ì§€ ë²ˆí˜¸ëŠ” ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤.")
            return
        with st.spinner("ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
            articles = fetch_real_estate_data(int(complex_no), max_pages=max_pages)
        if not articles:
            st.warning("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return
        df = process_data(articles)
        st.session_state.df = df
        st.success(f"ì´ {len(df)}ê°œ ë§¤ë¬¼ ì •ë³´ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤!")

    if 'df' in st.session_state and not st.session_state.df.empty:
        df = st.session_state.df
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"naver_real_estate_{complex_no}_{timestamp}.csv"

        tab1, tab2, tab3 = st.tabs(["ë°ì´í„°", "ë¶„ì„", "ì‹œê°í™”"])

        with tab1:
            st.markdown(create_download_link(df, filename), unsafe_allow_html=True)
            st.dataframe(df, use_container_width=True)

        with tab2:
            st.subheader("ë°ì´í„° ë¶„ì„")
            if 'ê°€ê²©(ì–µ)' in df:
                c1, c2, c3 = st.columns(3)
                c1.metric("í‰ê·  ê°€ê²©(ì–µ)", f"{df['ê°€ê²©(ì–µ)'].mean():.2f}")
                c2.metric("ìµœê³  ê°€ê²©(ì–µ)", f"{df['ê°€ê²©(ì–µ)'].max():.2f}")
                c3.metric("ìµœì € ê°€ê²©(ì–µ)", f"{df['ê°€ê²©(ì–µ)'].min():.2f}")

            st.subheader("ê±°ë˜ ìœ í˜•ë³„ í‰ê·  ê°€ê²©")
            if 'ê±°ë˜ìœ í˜•' in df and 'ê°€ê²©(ì–µ)' in df:
                trade_avg = df.groupby('ê±°ë˜ìœ í˜•')['ê°€ê²©(ì–µ)'].agg(['mean','count']).reset_index()
                trade_avg.columns = ['ê±°ë˜ìœ í˜•','í‰ê·  ê°€ê²©(ì–µ)','ë§¤ë¬¼ ìˆ˜']
                st.dataframe(trade_avg, use_container_width=True)

            st.subheader("ë©´ì ë³„ í‰ê·  ê°€ê²©")
            if 'ì „ìš©ë©´ì (ã¡)' in df and 'ê°€ê²©(ì–µ)' in df:
                df['ë©´ì êµ¬ê°„'] = pd.cut(df['ì „ìš©ë©´ì (ã¡)'], bins=[0,30,60,85,120,200],
                                      labels=['~30ã¡','30~60ã¡','60~85ã¡','85~120ã¡','120ã¡~'])
                area_avg = df.groupby('ë©´ì êµ¬ê°„')['ê°€ê²©(ì–µ)'].agg(['mean','count']).reset_index()
                area_avg.columns = ['ë©´ì êµ¬ê°„','í‰ê·  ê°€ê²©(ì–µ)','ë§¤ë¬¼ ìˆ˜']
                st.dataframe(area_avg, use_container_width=True)

        with tab3:
            st.subheader("ë°ì´í„° ì‹œê°í™”")
            if 'ê°€ê²©(ì–µ)' in df:
                st.subheader("ê°€ê²© ë¶„í¬")
                fig1 = px.histogram(df, x='ê°€ê²©(ì–µ)', nbins=20, title="ê°€ê²© ë¶„í¬")
                st.plotly_chart(fig1, use_container_width=True)

                if 'ì¸µì •ë³´' in df:
                    df['ì¸µ'] = df['ì¸µì •ë³´'].str.extract(r'(\d+)/').astype(float)
                    floor_df = df.dropna(subset=['ì¸µ'])
                    if not floor_df.empty:
                        st.subheader("ì¸µë³„ ê°€ê²©")
                        fig2 = px.scatter(
                            floor_df, x='ì¸µ', y='ê°€ê²©(ì–µ)',
                            color='ê±°ë˜ìœ í˜•', title="ì¸µë³„ ê°€ê²©",
                            labels={'ì¸µ':'ì¸µ','ê°€ê²©(ì–µ)':'ê°€ê²©(ì–µ)'}
                        )
                        st.plotly_chart(fig2, use_container_width=True)

                if 'ì „ìš©ë©´ì (ã¡)' in df:
                    st.subheader("ë©´ì ë³„ ê°€ê²©")
                    fig3 = px.scatter(
                        df, x='ì „ìš©ë©´ì (ã¡)', y='ê°€ê²©(ì–µ)',
                        color='ê±°ë˜ìœ í˜•', title="ë©´ì ë³„ ê°€ê²©",
                        labels={'ì „ìš©ë©´ì (ã¡)':'ì „ìš©ë©´ì (ã¡)','ê°€ê²©(ì–µ)':'ê°€ê²©(ì–µ)'}
                    )
                    st.plotly_chart(fig3, use_container_width=True)

                if 'ìœ„ë„' in df and 'ê²½ë„' in df:
                    st.subheader("ì§€ë„ ë³´ê¸°")
                    df['ìœ„ë„'] = pd.to_numeric(df['ìœ„ë„'], errors='coerce')
                    df['ê²½ë„'] = pd.to_numeric(df['ê²½ë„'], errors='coerce')
                    map_df = df.dropna(subset=['ìœ„ë„','ê²½ë„'])
                    if not map_df.empty:
                        fig4 = px.scatter_mapbox(
                            map_df, lat='ìœ„ë„', lon='ê²½ë„',
                            color='ê°€ê²©(ì–µ)', size='ì „ìš©ë©´ì (ã¡)',
                            hover_name='ë§¤ë¬¼ëª…',
                            hover_data=['ê°€ê²©','ê±°ë˜ìœ í˜•','ì¸µì •ë³´','ì „ìš©ë©´ì (ã¡)'],
                            zoom=15, mapbox_style="carto-positron"
                        )
                        st.plotly_chart(fig4, use_container_width=True)

if __name__ == "__main__":
    main()
